# ğŸ“Š Code Repositories æ·±åº¦è°ƒç ”æŠ¥å‘Š

## æ‰§è¡Œæ‘˜è¦

æœ¬æŠ¥å‘ŠåŸºäº Palantir Foundry Code Repositories å®˜æ–¹å¼€å‘è€…æ•™ç¨‹çš„è¯¦ç»†åˆ†æï¼Œæ¶µç›–äº† 10 ä»½æ ¸å¿ƒæ–‡æ¡£å†…å®¹ã€‚é€šè¿‡ç³»ç»Ÿç ”ç©¶ï¼Œæ­ç¤ºäº† Palantir Foundry æ•°æ®è½¬æ¢çš„å®Œæ•´æŠ€æœ¯ä½“ç³»ï¼ŒåŒ…æ‹¬ä»åŸºç¡€è½¬æ¢ã€å¢é‡è®¡ç®—åˆ°ç”Ÿäº§ç¯ä¿çš„å…¨æµç¨‹æœ€ä½³å®è·µã€‚

**æ ¸å¿ƒå‘ç°ï¼š** Code Repositories æ˜¯ Palantir Foundry ä¸­å®ç°æ•°æ®ç®¡é“è‡ªåŠ¨åŒ–çš„æ ¸å¿ƒå¼•æ“ï¼Œèåˆäº† PySpark ç¼–ç¨‹ã€æ•°æ®è´¨é‡ç®¡ç†ã€è½¯ä»¶å·¥ç¨‹æœ€ä½³å®è·µå’Œç”Ÿäº§ç¯ä¿æœºåˆ¶ã€‚

---

## ä¸€ã€ä½“ç³»æ¶æ„æ¦‚è§ˆ

### 1.1 æ ¸å¿ƒåŠŸèƒ½å®šä½

Code Repositories çš„æ ¸å¿ƒèŒè´£æ˜¯å°†ä¸šåŠ¡é€»è¾‘ä»£ç åŒ–ï¼Œä¸»è¦ä½“ç°åœ¨ä¸‰ä¸ªç»´åº¦ï¼š

| ç»´åº¦ | èŒè´£æè¿° | å…³é”®ç»„ä»¶ |
|------|--------|---------|
| **æ•°æ®è½¬æ¢** | å°†æ•°æ®ä»æºæ ¼å¼è½¬æ¢ä¸ºç›®æ ‡æ ¼å¼ | @transform_df, @transform è£…é¥°å™¨ |
| **å¤æ‚å¤„ç†** | å¤„ç†å¤šè¾“å…¥/å¤šè¾“å‡ºã€è¿æ¥ã€èšåˆç­‰ | PySpark DataFrame API |
| **è´¨é‡ä¿è¯** | ç¡®ä¿æ•°æ®ç¬¦åˆé¢„æœŸæ ‡å‡† | Data Expectations æ£€æŸ¥ |

### 1.2 æ–‡æ¡£ä½“ç³»å±‚çº§

```
åŸºç¡€å±‚ï¼ˆ01-07ï¼‰
â”œâ”€â”€ åŸºæœ¬è½¬æ¢ï¼ˆ01ï¼‰
â”œâ”€â”€ å¢é‡ä¼˜åŒ–ï¼ˆ02ï¼‰
â”œâ”€â”€ æµ‹è¯•ä¿éšœï¼ˆ03ï¼‰
â”œâ”€â”€ ä»£ç å¤ç”¨ï¼ˆ04-05ï¼‰
â””â”€â”€ è´¨é‡æ§åˆ¶ï¼ˆ06-07ï¼‰

é«˜é˜¶å±‚ï¼ˆ08-10ï¼‰
â”œâ”€â”€ ä»£ç å®¡æŸ¥ä¸æœ€ä½³å®è·µï¼ˆ08ï¼‰
â”œâ”€â”€ å¼€å‘æµç¨‹ä¸å·¥è‰ºï¼ˆ09ï¼‰
â””â”€â”€ PR ç®¡ç†ä¸ç”Ÿäº§å‘å¸ƒï¼ˆ10ï¼‰
```

---

## äºŒã€æ ¸å¿ƒæŠ€æœ¯ä½“ç³»

### 2.1 æ•°æ®è½¬æ¢æ¨¡å¼

#### 2.1.1 å•è¾“å…¥/å•è¾“å‡ºè½¬æ¢ï¼ˆæ–‡æ¡£ 01ï¼‰

**å®šä¹‰ï¼š** æœ€åŸºç¡€çš„è½¬æ¢æ¨¡å¼ï¼Œä¸€ä¸ªè¾“å…¥æ•°æ®é›†ç”Ÿæˆä¸€ä¸ªè¾“å‡ºã€‚

```
æºæ•°æ®é›† â†’ @transform_df â†’ è¾“å‡ºæ•°æ®é›†
```

**æŠ€æœ¯è¦ç‚¹ï¼š**
- ä½¿ç”¨ `@transform_df` è£…é¥°å™¨
- å‡½æ•°ç›´æ¥æ¥æ”¶ DataFrame ä½œä¸ºå‚æ•°
- å‡½æ•°è¿”å›å€¼å³ä¸ºè¾“å‡º DataFrame
- é€‚ç”¨åœºæ™¯ï¼šæ•°æ®æ¸…æ´—ã€åˆ—æ·»åŠ ã€åŸºç¡€è¿‡æ»¤

**å…¸å‹æ­¥éª¤ï¼š**
1. å®šä¹‰è¾“å…¥æ•°æ®é›†ï¼ˆå¤åˆ¶è·¯å¾„ï¼‰
2. å®šä¹‰è¾“å‡ºæ•°æ®é›†åç§°
3. ç¼–å†™ PySpark è½¬æ¢é€»è¾‘
4. ä½¿ç”¨ Preview éªŒè¯é€»è¾‘ï¼ˆåŸºäº 10,000 è¡Œï¼‰
5. ä½¿ç”¨ Build åœ¨å®Œæ•´æ•°æ®é›†ä¸Šæ‰§è¡Œ

#### 2.1.2 å¤šè¾“å…¥è¿æ¥è½¬æ¢

**æ ¸å¿ƒæ¦‚å¿µï¼š** åœ¨å•ä¸€è½¬æ¢ä¸­å¼•å…¥å¤šä¸ªæ•°æ®é›†è¿›è¡Œ Join æ“ä½œã€‚

**å…³é”®é—®é¢˜ - è¿æ¥çˆ†ç‚¸ï¼ˆJoin Explosionï¼‰ï¼š**
- åŸå› ï¼šJoin é”®ä¸å”¯ä¸€
- æ£€æŸ¥æ–¹æ³•ï¼šç‚¹å‡»åˆ—æ ‡é¢˜æŸ¥çœ‹ç›´æ–¹å›¾
- é¢„é˜²ï¼šBefore Joinï¼ŒéªŒè¯å…³é”®åˆ—çš„å”¯ä¸€æ€§

**Best Practiceï¼š**
```python
# âœ“ æ­£ç¡®åšæ³•ï¼šå…ˆæ¸…ç†åè¿æ¥
flights_df = flights.select("flight_id", "carrier_code").distinct()
result = flights_df.join(carrier, "carrier_code", "inner")

# âœ— é¿å…ï¼šç›´æ¥è¿æ¥å¯èƒ½å¯¼è‡´çˆ†ç‚¸
flights.join(carrier, "carrier_code")  # éœ€å…ˆéªŒè¯å”¯ä¸€æ€§
```

#### 2.1.3 å¤šè¾“å‡ºè½¬æ¢

**å®šä¹‰ï¼š** ä¸€ä¸ªè½¬æ¢ç”Ÿæˆå¤šä¸ªè¾“å‡ºæ•°æ®é›†ã€‚

**æŠ€æœ¯è½¬æ¢ï¼š**
- ä» `@transform_df` åˆ‡æ¢åˆ° `@transform`
- æ˜¾å¼ä½¿ç”¨ `.dataframe()` è¯»å–è¾“å…¥
- æ˜¾å¼ä½¿ç”¨ `.write_dataframe()` å†™å‡ºè¾“å‡º
- æ¯ä¸ªè¾“å‡ºéƒ½éœ€åœ¨è£…é¥°å™¨ä¸­å®šä¹‰

**åº”ç”¨åœºæ™¯ï¼š**
- æ•°æ®åˆ†ç±»å¤„ç†ï¼šå°†èˆªç­æ•°æ®æŒ‰ç›®çš„åœ°åˆ†ç»„è¾“å‡º
- ä¸­é—´æ€ç”Ÿæˆï¼šåŒæ—¶ç”Ÿæˆæ¸…æ´—ç‰ˆå’ŒåŸå§‹ç‰ˆæœ¬
- æŠ¥è¡¨ç”Ÿæˆï¼šä¸åŒç»´åº¦çš„æ±‡æ€»è¾“å‡º

### 2.2 å¢é‡è®¡ç®—ä¼˜åŒ–ï¼ˆæ–‡æ¡£ 02ï¼‰

#### 2.2.1 å¢é‡è½¬æ¢çš„ä»·å€¼

**é—®é¢˜æè¿°ï¼š** TB/PB çº§æ•°æ®å…¨é‡é‡ç®—ä»£ä»·æé«˜

**è§£å†³æ–¹æ¡ˆï¼š** åªè®¡ç®—æ–°å¢æ•°æ®

```
TB çº§æ•°æ® + 100 ä¸‡æ–°è¡Œ
â””â”€ ä¼ ç»Ÿæ–¹å¼ï¼šé‡ç®—æ‰€æœ‰æ•°æ®ï¼ˆhoursï¼‰
â””â”€ å¢é‡æ–¹å¼ï¼šä»…ç®—æ–°è¡Œï¼ˆsecondsï¼‰
```

#### 2.2.2 äº‹åŠ¡ç±»å‹å½±å“

| äº‹åŠ¡ç±»å‹ | è§¦å‘æ¡ä»¶ | å¢é‡æ€§ | åæœ |
|---------|--------|--------|------|
| è¿½åŠ äº‹åŠ¡ | ä¸Šä¼ æ–°æ–‡ä»¶åï¼ˆå¦‚ trans2.csvï¼‰ | âœ“ ä¿æŒ | ä»…å¤„ç†æ–°æ–‡ä»¶ï¼Œå†å²æ•°æ®æ—¶é—´æˆ³ä¸å˜ |
| æ›´æ–°äº‹åŠ¡ | ä¸Šä¼ åŒåæ–‡ä»¶æ›¿æ¢ | âœ— å¤±æ•ˆ | å¼ºåˆ¶å…¨é‡é‡ç®—ï¼Œæ‰€æœ‰è¡Œæ—¶é—´æˆ³æ›´æ–° |

**éªŒè¯æ–¹æ³•ï¼š** æ£€æŸ¥ `process_timestamp` åˆ—
- å…¨é‡æ„å»ºï¼šæ‰€æœ‰è¡Œæ—¶é—´æˆ³ä¸ºå½“å‰æ—¶é—´
- å¢é‡æ„å»ºï¼šä»…æ–°è¡Œæ—¶é—´æˆ³æ›´æ–°ï¼Œæ—§è¡Œä¿æŒä¸å˜

#### 2.2.3 ä»£ç å˜æ›´ä¸å¢é‡æ€§

**å…³é”®é—®é¢˜ï¼š** ä¿®æ”¹ä»£ç é€»è¾‘åï¼Œæ—§æ•°æ®æ˜¯å¦æ›´æ–°ï¼Ÿ

**ç­”æ¡ˆï¼š** é»˜è®¤ä¸æ›´æ–°

**ç°è±¡ï¼š** æ·»åŠ æ–°åˆ—åï¼Œæ—§æ•°æ®è¯¥åˆ—æ˜¾ç¤º NULL

**è§£å†³æ–¹æ¡ˆï¼š** ä½¿ç”¨ Semantic Versioning

```python
@incremental(semantic_version="1")  # ç‰ˆæœ¬å·å˜æ›´
def transform(ctx, input):
    # æ–°é€»è¾‘ä¼šå¼ºåˆ¶å…¨é‡é‡ç®—
    return df.withColumn("new_col", ...)
```

### 2.3 å•å…ƒæµ‹è¯•ä½“ç³»ï¼ˆæ–‡æ¡£ 03ï¼‰

#### 2.3.1 ç¯å¢ƒè®¾ç½®

**å¿…è¦æ­¥éª¤ï¼š**
1. åˆ›å»ºå¼€å‘åˆ†æ”¯ï¼ˆMaster é€šå¸¸é”å®šï¼‰
2. æ£€æŸ¥ `build.gradle` ä¸­ pytest æ’ä»¶æ˜¯å¦æ¿€æ´»
3. åœ¨ `source` ç›®å½•åˆ›å»º `test` åŒ…
4. éµå¾ªå‘½åè§„èŒƒï¼š`test_*.py`

#### 2.3.2 æµ‹è¯•é€»è¾‘æå–

**åŸåˆ™ï¼š** å°†ç®¡é“é€»è¾‘ä¸è¾“å…¥/è¾“å‡ºè§£è€¦

```python
# ä»ç®¡é“ä¸­æå–çº¯å‡½æ•°
def mark_null_tail_numbers(df: DataFrame) -> DataFrame:
    """è¿™æ˜¯å¯æµ‹è¯•çš„çº¯å‡½æ•°"""
    return df.withColumn("tail_number",
                         when(col("tail_number").isNull(), "UNKNOWN")
                         .otherwise(col("tail_number")))

# åœ¨æµ‹è¯•ä¸­åˆ›å»ºæµ‹è¯•æ•°æ®å¹¶éªŒè¯
def test_mark_null_tail_numbers(spark_context):
    test_data = spark_context.createDataFrame([...], schema)
    result = mark_null_tail_numbers(test_data)
    assert result.filter(col("tail_number") == "UNKNOWN").count() == 1
```

#### 2.3.3 å¸¸è§é”™è¯¯ä¸ Linter é˜²æŠ¤

**å…¸å‹é”™è¯¯ï¼šä½¿ç”¨ `is` æ¯”è¾ƒå­—ç¬¦ä¸²**

```python
# âœ— é”™è¯¯ï¼šæ¯”è¾ƒå†…å­˜å¼•ç”¨è€Œéå†…å®¹
assert tail_number is "UNKNOWN"

# âœ“ æ­£ç¡®ï¼šæ¯”è¾ƒå­—ç¬¦ä¸²å†…å®¹
assert tail_number == "UNKNOWN"
```

**é˜²æŠ¤æœºåˆ¶ï¼š** Foundry IDE å†…ç½® Linter
- ç»¿è‰²æ³¢æµªçº¿æç¤º
- æ‚¬åœæ˜¾ç¤º"ä½¿ç”¨ equals æ¯”è¾ƒå­—ç¬¦ä¸²å­—é¢é‡"
- è‡ªåŠ¨ä»£ç æ£€æŸ¥é˜²æ­¢å¸¸è§é™·é˜±

### 2.4 ä»£ç å¤ç”¨ä½“ç³»ï¼ˆæ–‡æ¡£ 04-05ï¼‰

#### 2.4.1 Python åº“åˆ›å»ºæµç¨‹

**ç¬¬ä¸€æ­¥ï¼šåˆå§‹åŒ– Python Library ç±»å‹ä»“åº“**
```
Shared Resources æ–‡ä»¶å¤¹
â””â”€â”€ aviation_cleaning_libraryï¼ˆæ–°æ–‡ä»¶å¤¹ï¼‰
    â””â”€â”€ Create Repository â†’ Select "Python Library"
```

**ç¬¬äºŒæ­¥ï¼šç»„ç»‡ä»£ç ç»“æ„**
- é‡å‘½åé»˜è®¤åŒ…ä¸ºæœ‰æ„ä¹‰çš„åç§°ï¼ˆå¦‚ `cleaner`ï¼‰
- åœ¨åŒ…ä¸‹åˆ›å»ºå…·ä½“å®ç°æ–‡ä»¶ï¼ˆå¦‚ `function.py`ï¼‰
- å¤„ç†å¤–éƒ¨ä¾èµ–å¯¼å…¥ï¼Œä½¿ç”¨ Lint éªŒè¯

**ç¬¬ä¸‰æ­¥ï¼šå‘å¸ƒåº“ï¼ˆå…³é”®æ­¥éª¤ï¼‰**

ä»…æäº¤ä»£ç ä¸ä¼šå‘å¸ƒåº“ï¼å¿…é¡»åˆ›å»º Tagï¼š

```
1. ç‚¹å‡» Branches é€‰é¡¹å¡
2. è¿›å…¥ Tags é¡µé¢
3. åˆ›å»ºæ–° Tagï¼ˆå¦‚ v0.1ï¼‰
4. ç­‰å¾… Checks é€šè¿‡ â†’ åº“è‡ªåŠ¨å‘å¸ƒ
```

**å‘å¸ƒéªŒè¯ï¼š** æŸ¥çœ‹ `library publish` æ—¥å¿—
- Skipï¼šéœ€è¦åˆ›å»º Tag
- Successï¼šåº“å·²å‘å¸ƒ

#### 2.4.2 åº“çš„æ¶ˆè´¹æµç¨‹

**ç¬¬ä¸€æ­¥ï¼šåˆ›å»ºåˆ†æ”¯**
- Master åˆ†æ”¯é€šå¸¸è¢«ä¿æŠ¤
- "Add library" æŒ‰é’®åªåœ¨å¼€å‘åˆ†æ”¯å¯ç”¨

**ç¬¬äºŒæ­¥ï¼šæ·»åŠ ä¾èµ–**
1. è¿›å…¥ Libraries é€‰é¡¹å¡
2. æœç´¢åº“åç§°
3. ç‚¹å‡»æ·»åŠ 
4. æ£€æŸ¥ `meta.yaml` ç¡®è®¤ä¾èµ–å·²æ·»åŠ 
5. æäº¤å˜æ›´

**ç¬¬ä¸‰æ­¥ï¼šä»£ç é‡æ„**
```python
# ä»åº“æ ¹åŒ…å¯¼å…¥å‡½æ•°
from cleaner.function import data_asset_pass_flattener

# åˆ é™¤åŸæœ‰æœ¬åœ°å®šä¹‰
# ä½¿ç”¨å¯¼å…¥çš„å‡½æ•°æ›¿æ¢
result = data_asset_pass_flattener(df)
```

**ç¬¬å››æ­¥ï¼šå¤„ç† CI å†²çª**

å¸¸è§é—®é¢˜ï¼šPython ç‰ˆæœ¬ä¸åŒ¹é…
```
é¡¹ç›®ä½¿ç”¨ Python 3.6ï¼Œåº“éœ€è¦ 3.8
â†“
ä¿®æ”¹ meta.yaml ä¸­çš„ Python ç‰ˆæœ¬ä¾èµ–ä¸º 3.8.*
â†“
é‡æ–°æäº¤
```

**æ€§èƒ½æç¤ºï¼š** Conda ä¾èµ–æ ‘è§£æå¯èƒ½è€—æ—¶é•¿
- åœ¨ conda.yaml ä¸­å›ºå®šç‰ˆæœ¬å·å¯åŠ é€Ÿ CI æ£€æŸ¥

### 2.5 æ•°æ®æœŸæœ›ä¸è´¨é‡ç®¡ç†ï¼ˆæ–‡æ¡£ 06ï¼‰

#### 2.5.1 æ ¸å¿ƒç†å¿µ

**ç›®çš„ï¼š** é˜²æ­¢è„æ•°æ®åœ¨ç®¡é“ä¸­ä¼ æ’­

**åŸåˆ™ï¼š** "è¿‡æœŸ > é”™è¯¯"
- è¿‡æœŸæ•°æ®ï¼šç”¨æˆ·ç­‰å¾…æ–°æ•°æ®ï¼ˆå¯æ¥å—ï¼‰
- é”™è¯¯æ•°æ®ï¼šè¿›å…¥ä¸‹æ¸¸ç³»ç»Ÿï¼ˆä¸¥é‡åæœï¼‰

#### 2.5.2 æ£€æŸ¥ç±»å‹ä¸å®ç°

**ç±»å‹ 1ï¼šé€»è¾‘æ¯”è¾ƒæ£€æŸ¥**

```python
# æ£€æŸ¥ï¼šå‡ºå‘æ—¶é—´å¿…é¡»æ—©äºåˆ°è¾¾æ—¶é—´
check(departure).is_before(arrival).named("departure should be before arrival")
```

**ç±»å‹ 2ï¼šè¾“å…¥æ•°æ®æ ¼å¼éªŒè¯**

```python
# æ£€æŸ¥ï¼šå§‹å‘åœ°æœºåœºä»£ç å¿…é¡»æ˜¯ 3 ä¸ªå­—ç¬¦
check(origin).match_regex("^[A-Z]{3}$").named("airport code is 3 chars")
```

**å¸¸è§é™·é˜±ï¼šä½¿ç”¨ `.size()` æ£€æŸ¥å­—ç¬¦ä¸²é•¿åº¦**
```python
# âœ— é”™è¯¯ï¼šsize() ç”¨äºæ•°ç»„/æ˜ å°„
check(origin).filter(col("length") == 3)  # æ„å»ºå¤±è´¥

# âœ“ æ­£ç¡®ï¼šä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼
check(origin).rlike("^[A-Z]{3}$")
```

#### 2.5.3 æµ‹è¯•ä¸å¤±è´¥ç­–ç•¥

**é¢„è§ˆæ¨¡å¼ï¼ˆPreviewï¼‰**
- åŸºäºå°æ•°æ®æ ·æœ¬ï¼ˆå¦‚ 1,000 è¡Œï¼‰
- å¿«é€Ÿè¿­ä»£å¼€å‘
- æ˜¾ç¤ºå…·ä½“å¤±è´¥æ ·æœ¬

**å…¨é¢æ„å»ºï¼ˆBuildï¼‰**
- æ£€æŸ¥å®Œæ•´æ•°æ®é›†
- æŠ¥å‘Šå¤±è´¥è¡Œæ•°
- ç”Ÿæˆå¤±è´¥è¯¦æƒ…

**å¤±è´¥ç­–ç•¥é…ç½®**

| ç­–ç•¥ | è¡Œä¸º | åœºæ™¯ |
|------|------|------|
| Fail Build | æ£€æŸ¥å¤±è´¥ â†’ æ„å»ºåœæ­¢ | å¼ºåˆ¶æ•°æ®è´¨é‡ |
| Warning | æ£€æŸ¥å¤±è´¥ â†’ ä»…å‘è­¦å‘Š | å‘ŠçŸ¥ä½†å…è®¸ |

### 2.6 å¤æ‚æ•°æ®å¤„ç†ï¼ˆæ–‡æ¡£ 07 - Excel è§£æï¼‰

#### 2.6.1 å¤„ç†æµç¨‹

**ç¬¬ä¸€æ­¥ï¼šå¯¼å…¥ Excel æ–‡ä»¶**
```
æ‹–æ”¾ Excel æ–‡ä»¶
â””â”€â”€ é€‰æ‹©"Upload to dataset without schema"
â””â”€â”€ é‡å‘½åä¸ºæœ‰æ„ä¹‰çš„åç§°ï¼ˆå¦‚ favorite_colorsï¼‰
```

**ç¬¬äºŒæ­¥ï¼šè½¬æ¢ç±»å‹é€‰æ‹©**
```python
# âœ— ä¸èƒ½ä½¿ç”¨ transform_dfï¼ˆç”¨äºè¡¨åˆ°è¡¨ï¼‰
@transform_df
def my_transform(df):
    pass

# âœ“ å¿…é¡»ä½¿ç”¨ transformï¼ˆç”¨äºæ–‡ä»¶åˆ°è¡¨ï¼‰
@transform
def my_transform(ctx, output):
    pass
```

**ç¬¬ä¸‰æ­¥ï¼šä¾èµ–å¯¼å…¥**
```python
from pyspark.sql import Row
from pyspark.sql.types import StringType, StructType, StructField
import xlrd  # Excel è¯»å–åº“
```

#### 2.6.2 Excel è¯»å–é€»è¾‘

**æ–‡ä»¶ç³»ç»Ÿæ“ä½œï¼š**
```python
# è·å–è¾“å…¥æ–‡ä»¶åˆ—è¡¨
file_status = ctx.run_input.filesystem().file_status()

# ä½¿ç”¨ glob ç­›é€‰ç‰¹å®šæ–‡ä»¶ç±»å‹
excel_files = [f for f in file_status if f.name.endswith(".xlsx")]

# æ–­è¨€ä»…æœ‰ä¸€ä¸ªæ–‡ä»¶
assert len(excel_files) == 1
latest_file = excel_files[0]

# ä»¥äºŒè¿›åˆ¶æ¨¡å¼æ‰“å¼€æ–‡ä»¶ï¼ˆExcel æ˜¯éæ–‡æœ¬æ ¼å¼ï¼‰
with ctx.run_input.filesystem().open(latest_file.path, "rb") as f:
    workbook = xlrd.open_workbook(file_contents=f.read())
```

**æ•°æ®æå–ï¼š**
```python
# é€‰æ‹©å·¥ä½œè¡¨
sheet = workbook.sheet_by_index(0)

# æå–è¡¨å¤´å’Œæ•°æ®è¡Œ
headers = sheet.row_values(0)  # ç¬¬ä¸€è¡Œæ˜¯è¡¨å¤´
rows = []

for row_idx in range(1, sheet.nrows):
    row_data = sheet.row_values(row_idx)
    rows.append(Row(*[tuple(zip(headers, row_data))]))
```

**Schema å®šä¹‰ä¸è¾“å‡ºï¼š**
```python
# å®šä¹‰ Schema
schema = StructType([
    StructField("name", StringType()),
    StructField("age", StringType()),
    StructField("color", StringType()),
])

# åˆ›å»º DataFrame
df = ctx.spark_session.createDataFrame(rows, schema)

# å†™å…¥è¾“å‡º
output.write_dataframe(df)
```

---

## ä¸‰ã€ä»£ç å®¡æŸ¥ä¸æœ€ä½³å®è·µï¼ˆæ–‡æ¡£ 08ï¼‰

### 3.1 æ ¸å¿ƒåŸåˆ™ï¼šExplicit, Contextual, Readable

#### 3.1.1 å¯è¯»æ€§ä¸æ„å›¾æ¸…æ™°åº¦

**é—®é¢˜ 1ï¼šè¿‡é•¿ä»£ç è¡Œ**
```python
# âœ— éš¾ä»¥é˜…è¯»
flights.select("origin", "destination", "arrival_time").filter(col("arrival_time") > "2023-01-01").groupBy("origin").agg(count("*"))

# âœ“ ä½¿ç”¨éšå¼ç»­è¡Œ
(flights
    .select("origin", "destination", "arrival_time")
    .filter(col("arrival_time") > "2023-01-01")
    .groupBy("origin")
    .agg(count("*")))
```

**é—®é¢˜ 2ï¼šåˆ—é‡å‘½åä¸å¤Ÿæ˜¾å¼**
```python
# âœ— ä½¿ç”¨ä¸­é—´åç§°
df = df.withColumnRenamed("col_a", "temp_col")
df = df.withColumnRenamed("temp_col", "airport")

# âœ“ ç›´æ¥ä½¿ç”¨æœ€ç»ˆåç§°
df = df.withColumnRenamed("col_a", "airport")
```

**é—®é¢˜ 3ï¼šä»£ç å±€éƒ¨æ€§å·®**
```python
# âœ— å˜é‡å®šä¹‰ç¦»ä½¿ç”¨ç‚¹è¿œ
primary_key = col("flight_id")  # ä¸Šé¢ 50 è¡Œå®šä¹‰
...
df = df.withColumn("pk", primary_key)  # ä¸‹é¢ä½¿ç”¨

# âœ“ å˜é‡å®šä¹‰é è¿‘ä½¿ç”¨ç‚¹
df = df.withColumn("pk", col("flight_id"))

# âœ— UDF å®šä¹‰ä¸å±€éƒ¨
def clean_tail_number(x):  # æ–‡ä»¶é¡¶éƒ¨
    return x if x else "UNKNOWN"

# âœ“ ä½¿ç”¨è£…é¥°å™¨ä½¿ UDF å±€éƒ¨åŒ–
df = df.withColumn("tail_number",
    udf(lambda x: x if x else "UNKNOWN")(col("tail_number")))
```

#### 3.1.2 PySpark æ“ä½œçš„æœ€ä½³å®è·µ

**Union æ“ä½œï¼š**
```python
# âœ— æ™®é€š union æ˜“å‡ºé”™
df1.union(df2)  # ä»…æŒ‰ä½ç½®å¯¹é½åˆ—

# âœ“ unionByName æ›´å®‰å…¨
df1.unionByName(df2)  # æŒ‰åˆ—åå¯¹é½
```

**Join æ“ä½œï¼š**
```python
# âœ— éšå¼ join ç±»å‹ï¼ˆé»˜è®¤ innerï¼‰
flights.join(carriers, "carrier_code")

# âœ“ æ˜¾å¼æŒ‡å®š join ç±»å‹å’Œä½¿ç”¨å…³é”®å­—å‚æ•°
flights.join(carriers, on="carrier_code", how="inner")

# âœ— Join åæ‰æ¸…ç†
flights.join(carriers, "carrier_code").select("flights.*")

# âœ“ Join å‰æ¸…ç†ï¼Œé¿å…é‡å¤åˆ—
(flights
    .select("flight_id", "carrier_code", ...)
    .join(carriers, "carrier_code", "inner"))

# âœ— ä¸æŒ‡å®š join ç±»å‹
flights.join(carriers, flight.carrier_code == carriers.carrier_code)

# âœ“ è‡ªç„¶è¿æ¥ï¼šé€šè¿‡åˆ—åé‡å‘½åå®ç°
carriers_renamed = carriers.withColumnRenamed("carrier_code", "carrier_id")
flights.join(carriers_renamed, col("carrier_code") == col("carrier_id"), "inner")
```

**Broadcast Join ä¼˜åŒ–ï¼š**
```python
# é»˜è®¤ç¦ç”¨å¹¿æ’­è¿æ¥æ—¶
# âœ— ä¸æŒ‡å®š
flights.join(carriers, "carrier_code")  # å¯èƒ½æ€§èƒ½å·®

# âœ“ æ˜¾å¼æŒ‡å®šå¹¿æ’­
flights.join(carriers.hint("broadcast"), "carrier_code")
```

#### 3.1.3 é¿å…çš„"ä»£ç å¼‚å‘³"

**å¼‚å‘³ 1ï¼šå°†æ•°æ®æ‹‰å› Driver ç«¯**
```python
# âœ— ä¸å¥½çš„åšæ³•
mapping_dict = carrier_df.select("id", "name").collect()  # æ‹‰å›å†…å­˜
mapping = {row[0]: row[1] for row in mapping_dict}
result_df = flights_df.withColumn("carrier_name",
    col("carrier_id").isin([k for k in mapping.keys()]))

# âœ“ ä½¿ç”¨ Spark Join
result_df = (flights_df
    .join(carriers_df, "carrier_id", "left")
    .select("flights_df.*", "carriers_df.name"))
```

**å¼‚å‘³ 2ï¼šè„†å¼±çš„ä¸»é”®æ„å»º**
```python
# âœ— ä½¿ç”¨ concatï¼ˆä¸€ä¸ª null ä½¿æ•´ä¸ªè¡¨è¾¾å¼ä¸º nullï¼‰
df = df.withColumn("composite_key",
    concat(col("flight_id"), lit("-"), col("origin")))
# å¦‚æœ origin æœ‰ nullï¼Œcomposite_key ä¸º null

# âœ“ æ›´æ˜ç¡®çš„å¤„ç†
df = df.withColumn("composite_key",
    when(col("flight_id").isNotNull() & col("origin").isNotNull(),
         concat(col("flight_id"), lit("-"), col("origin")))
    .otherwise(col("flight_id")))
```

**å¼‚å‘³ 3ï¼šä¸æŒ‡å®šåˆ—çš„ drop_duplicates**
```python
# âœ— æ£€æŸ¥æ‰€æœ‰åˆ—ï¼ˆåŒ…å« null å’Œæ‚æ•°æ®çš„åˆ—ï¼‰
df = df.dropDuplicates()  # å¯èƒ½ä¸¢å¤±å¤§é‡æ•°æ®

# âœ“ æŒ‡å®šåˆ—å­é›†
df = df.dropDuplicates(["flight_id", "date"])
```

**å¼‚å‘³ 4ï¼šä½¿ç”¨ fillna å¡«å……å‡å€¼**
```python
# âœ— ç”¨å‡å€¼æ›¿æ¢ null
df = df.fillna("UNKNOWN")  # ä¸§å¤± null è¯­ä¹‰

# âœ“ ä¿ç•™ nullï¼ˆåœ¨ Spark ç®—å­ä¸­æœ‰æ›´å¥½è¯­ä¹‰ï¼‰
df = df.filter(col("value").isNotNull())  # æˆ–åœ¨éœ€è¦æ—¶æ˜¾å¼å¤„ç†
```

### 3.2 å‡½æ•°ä¸ UDF é‡æ„

**é‡æ„åŸåˆ™ 1ï¼šæå–çº¯å‡½æ•°**
```python
# å¦‚æœ UDF ä¸ä¾èµ–å±€éƒ¨å˜é‡ï¼Œç§»å‡ºä¸»ä½“
def is_valid_airport(airport_code):
    return len(airport_code) == 3

# åœ¨ transform ä¸­ä½¿ç”¨
udf_is_valid = udf(is_valid_airport, BooleanType())
df = df.filter(udf_is_valid(col("origin")))
```

**é‡æ„åŸåˆ™ 2ï¼šä½¿ç”¨"æ—©é€€"æ¨¡å¼**
```python
# âœ— å¤æ‚åµŒå¥—æ¡ä»¶
def format_flight_info(flight_id, origin, destination):
    if flight_id:
        if origin:
            if destination:
                return f"{flight_id}: {origin} -> {destination}"
            else:
                return None
        else:
            return None
    else:
        return None

# âœ“ æ—©é€€æ¨¡å¼
def format_flight_info(flight_id, origin, destination):
    if not flight_id or not origin or not destination:
        return None
    return f"{flight_id}: {origin} -> {destination}"
```

---

## å››ã€å¼€å‘æµç¨‹ä¸ç”Ÿäº§å·¥è‰ºï¼ˆæ–‡æ¡£ 09ï¼‰

### 4.1 åˆ†æ”¯ç®¡ç†ä¸ç”Ÿäº§ç¨³å®šæ€§

#### 4.1.1 Master åˆ†æ”¯ä¿æŠ¤

**ç›®æ ‡ï¼š** ç¡®ä¿ç”Ÿäº§ç¯å¢ƒæ•°æ®ç®¡é“ç¨³å®š

**æœºåˆ¶ï¼š**
1. Master åˆ†æ”¯è®¾ä¸ºå—ä¿æŠ¤çŠ¶æ€
2. è®¾ç½®æ‰¹å‡†äººç»„ï¼ˆGroup of Approversï¼‰è€Œéå•äºº
3. æ‰€æœ‰å¼€å‘åœ¨ç‹¬ç«‹åˆ†æ”¯è¿›è¡Œ

**åˆ†æ”¯å‘½åè§„èŒƒï¼š**
```
feature/user-name/descriptive-task-name
fix/user-name/issue-description
refactor/user-name/optimization-details
```

#### 4.1.2 å¼€å‘å·¥ä½œæµ

```
main/master (å—ä¿æŠ¤)
    â†“
åˆ›å»ºç‰¹æ€§åˆ†æ”¯
    â†“ æœ¬åœ°å¼€å‘ã€æäº¤
è¿›è¡Œä»£ç å®¡æŸ¥
    â†“
é€šè¿‡ PR åˆå¹¶
    â†“
ç­‰å¾… Master æ£€æŸ¥
    â†“
æ‰‹åŠ¨æ„å»ºæˆ–ç­‰å¾… Schedule
    â†“
éªŒè¯ç”Ÿäº§æ•°æ®
```

### 4.2 ä»£ç è´¨é‡ä¸é£æ ¼

**é£æ ¼æŒ‡å—éµå¾ªçš„ç›Šå¤„ï¼š**
- æé«˜ä»£ç å¯è¯»æ€§
- å‡å°‘ Bug å€¾å‘
- ä¾¿äºæ—¥åç»´æŠ¤
- æé«˜å›¢é˜Ÿåä½œæ•ˆç‡

### 4.3 é¢„è§ˆä¸è¿­ä»£å¼€å‘

#### 4.3.1 Preview æœºåˆ¶

**ç‰¹æ€§ï¼š** åŸºäº 10,000 è¡Œæ•°æ®æ ·æœ¬
- âœ“ å¿«é€Ÿæ£€æŸ¥è¯­æ³•é”™è¯¯
- âœ“ éªŒè¯åˆ—åæ˜¯å¦æ­£ç¡®
- âœ— ä¸èƒ½éªŒè¯ç»å¯¹å‡†ç¡®æ€§ï¼ˆèšåˆ/Join ç»Ÿè®¡å¯èƒ½ä¸å‡†ï¼‰

#### 4.3.2 è‡ªå®šä¹‰è¾“å…¥ç­–ç•¥ä¼˜åŒ–

**é—®é¢˜ï¼š** Preview çš„é‡‡æ ·å¯èƒ½é—æ¼è¾¹ç•Œæƒ…å†µ

**è§£å†³æ–¹æ¡ˆï¼š** é…ç½®è¾“å…¥ç­–ç•¥ï¼ˆInput Strategyï¼‰

```python
# ä¾‹ï¼šåªé¢„è§ˆç‰¹å®šæœºåœºçš„æ•°æ®
filter: origin == "SFO"
```

**ä¼˜åŠ¿ï¼š**
- é’ˆå¯¹ç‰¹å®šæ¡ˆä¾‹è°ƒè¯•
- é¿å…é‡‡æ ·å¯¼è‡´çš„å¤±å‡†
- å¯ä¿å­˜è¿‡æ»¤å™¨ä¾›åç»­ä½¿ç”¨

### 4.4 è°ƒè¯•å·¥å…·

**åŠŸèƒ½ï¼š**
- è®¾ç½®æ–­ç‚¹ï¼ˆBreakpointsï¼‰
- æŸ¥çœ‹å˜é‡å…ƒæ•°æ®ï¼ˆSchemaï¼‰
- æ£€æŸ¥ç‰¹å®šæ­¥éª¤çš„ DataFrame å†…å®¹
- åœ¨ Console æ‰§è¡Œæµ‹è¯•æ“ä½œ

**ç¤ºä¾‹ï¼š**
```python
# åœ¨è°ƒè¯•å™¨ Console ä¸­è¿è¡Œ
source_df.count()  # æ£€æŸ¥è¡Œæ•°
source_df.printSchema()  # æŸ¥çœ‹ Schema
source_df.filter(col("origin") == "SFO").show()  # æ£€æŸ¥æ•°æ®
```

### 4.5 å•å…ƒæµ‹è¯•

**é‡è¦æ€§ï¼š** æä¾›é¢å¤–çš„éŸ§æ€§ä¿éšœå±‚
- å½“ä¿®æ”¹è½¬æ¢é€»è¾‘æ—¶å¿…é¡»æ›´æ–°æµ‹è¯•
- ç¡®ä¿å›å½’æµ‹è¯•ï¼ˆRegression Testingï¼‰

### 4.6 æäº¤ä¸æ„å»ºæµç¨‹

#### 4.6.1 æäº¤ä¿¡æ¯æœ€ä½³å®è·µ

```
âœ— ä¸å¥½çš„æäº¤ä¿¡æ¯
Update transform
Fixed bugs

âœ“ è‰¯å¥½çš„æäº¤ä¿¡æ¯
Rename distance_column to average_distance_from_origin and update Join logic
Add validation checks for airport codes
```

#### 4.6.2 æ„å»ºæ–¹å¼

**æ–¹å¼ 1ï¼šä»ä»£ç æ„å»º**
```
ç‚¹å‡»ä»£ç ç•Œé¢ Build æŒ‰é’®
    â†“
è¿è¡Œæ£€æŸ¥ï¼ˆSyntax + Librariesï¼‰
    â†“
å¼€å§‹æ„å»º
    â†“
ç”Ÿæˆè¾“å‡ºæ•°æ®é›†
```

**æ–¹å¼ 2ï¼šä»æ•°æ®è¡€ç¼˜æ„å»ºï¼ˆMonocleï¼‰**
```
è¿›å…¥ Explore Lineage
    â†“
å¯è§†åŒ–å¤šä¸ªæ•°æ®é›†çš„ä¾èµ–
    â†“
é€‰æ‹©æ„å»º
```

#### 4.6.3 å…³é”®é™·é˜±ï¼šMonocle ä¸­çš„æ£€æŸ¥å»¶è¿Ÿ

**é—®é¢˜ï¼š** åœ¨ Monocle ä¸­ç‚¹å‡»æ„å»ºæ—¶ï¼Œæ£€æŸ¥å¯èƒ½æœªå®Œæˆ

**åæœï¼š** ç³»ç»Ÿä½¿ç”¨æ—§ä»£ç æ„å»ºï¼ˆé¿å…æ­£åœ¨å¼€å‘çš„ä»£ç é˜»å¡ï¼‰

**è§£å†³ï¼š** å¿…é¡»å…ˆç­‰å¾… Master æ£€æŸ¥å®Œæˆå†æ„å»º

### 4.7 èµ„æºå¼•ç”¨ä¼˜åŒ–

#### 4.7.1 ä½¿ç”¨ RID æ›¿ä»£æ–‡ä»¶è·¯å¾„

**é—®é¢˜ï¼š** æ–‡ä»¶è·¯å¾„æ˜“æ–­è£‚
- ç§»åŠ¨æ–‡ä»¶ä½ç½® â†’ è·¯å¾„å¤±æ•ˆ
- é‡å‘½åæ–‡ä»¶å¤¹ â†’ ä»£ç éœ€æ”¹åŠ¨

**è§£å†³ï¼š** ä½¿ç”¨ RIDï¼ˆResource Identifierï¼‰

```python
# âœ— ä½¿ç”¨è·¯å¾„ï¼ˆæ˜“æ–­è£‚ï¼‰
@transform_df(input_data=inputs.my_project.raw_flights)
def my_transform(flights_df):
    ...

# âœ“ ä½¿ç”¨ RIDï¼ˆç¨³å¥ï¼‰
@transform_df(input_data="ri.foundry.main.dataset.abc123")
def my_transform(flights_df):
    ...
```

**ä¼˜åŠ¿ï¼š**
- è·¯å¾„æ”¹åŠ¨ä¸å½±å“ä»£ç 
- é¿å…å¤„ç† `transforms-shrinkwrap.yaml` å†²çª
- æ›´å®¹æ˜“è·¨é¡¹ç›®å¼•ç”¨

---

## äº”ã€PR ç®¡ç†ä¸ç”Ÿäº§å‘å¸ƒï¼ˆæ–‡æ¡£ 10ï¼‰

### 5.1 åˆ›å»º PR å‰çš„å‡†å¤‡

#### 5.1.1 ä¸ Master åŒæ­¥

**ç›®çš„ï¼š** é¿å…åç»­åˆå¹¶å†²çª

```
å½“å‰åˆ†æ”¯
    â†“
ç‚¹å‡» Merge â†’ "Merge from Branch master"
    â†“
è·å¾—æœ€æ–°ä»£ç 
    â†“
æå‰å‘ç°å†²çª
```

#### 5.1.2 è‡ªæˆ‘å®¡æŸ¥

**æ£€æŸ¥æ¸…å•ï¼š**
- [ ] ä»£ç é€»è¾‘æ˜¯å¦åˆç†
- [ ] æ˜¯å¦åˆ é™¤äº†ä¸´æ—¶æµ‹è¯•ä»£ç 
- [ ] æ˜¯å¦éµå¾ªé£æ ¼æŒ‡å—
- [ ] æ˜¯å¦æœ‰æ˜æ˜¾çš„æ€§èƒ½é—®é¢˜

### 5.2 PR åˆ›å»ºä¸æè¿°

#### 5.2.1 æ ‡é¢˜è§„èŒƒ

```
âœ— æ¨¡ç³Šæ ‡é¢˜
Update transform
Fix bug

âœ“ æè¿°æ€§æ ‡é¢˜
Rename column origin to airport_code and refactor Join logic for carriers table
Add Data Expectations to validate arrival_time > departure_time
```

#### 5.2.2 PR æè¿°æ£€æŸ¥æ¸…å•ï¼ˆæ ¸å¿ƒè¦æ±‚ï¼‰

**ç»“æ„ï¼š**
```markdown
## å˜æ›´æ‘˜è¦
- å¯¹ flights_raw è¿›è¡Œäº†æ•°æ®æ¸…æ´—
- æ·»åŠ äº†æ–°çš„ "aircraft_type" åˆ—ï¼Œé€šè¿‡ Join carriers è¡¨è·å–
- ä¼˜åŒ–äº† Join é€»è¾‘ï¼Œä½¿ç”¨ broadcast hint åŠ é€Ÿ

## æ„å»ºé“¾æ¥
[ç‚¹å‡»æ­¤å¤„æŸ¥çœ‹æ„å»ºç»“æœ](link_to_build)
- flights_raw: âœ“ Success
- flights_cleaned: âœ“ Success
- dashboards ä¸‹æ¸¸æ„å»º: âœ“ Success

## ä¸ Master å¯¹æ¯”
[æ•°æ®ç»“æ„å¯¹æ¯”](compare_link)
- è¡Œæ•°ï¼š420 ä¸‡ â†’ 418 ä¸‡ï¼ˆ2 ä¸‡è¡Œå› è´¨é‡æ£€æŸ¥å¤±è´¥è¢«è¿‡æ»¤ï¼‰
- æ–°å¢åˆ—ï¼šaircraft_typeï¼ˆéç©ºç‡ 99.5%ï¼‰
- ç©ºå€¼å˜åŒ–ï¼šæ— å¼‚å¸¸å¢é•¿

## å†…å®¹æ·±åº¦éªŒè¯ï¼ˆContour åˆ†æï¼‰
[è¯¦ç»†æ•°æ®å¯¹æ¯”](contour_link)
ç­›é€‰ç‰¹å®šèˆªç­ ID å¯¹æ¯”æ–°æ—§ç‰ˆæœ¬ç»“æœ

## åç»­è¡ŒåŠ¨
- [ ] Schedule éœ€ä»æ¯æ—¥æ”¹ä¸ºæ¯å°æ—¶æ›´æ–°
- [ ] Ontology ç¼–è¾‘å™¨éœ€é‡æ–°è¿æ¥ aircraft_type åˆ—
- [ ] Workshop åº”ç”¨éœ€æ›´æ–°å­—æ®µæ˜¾ç¤º
- [ ] é€šçŸ¥ä¸‹æ¸¸æ•°æ®æ¶ˆè´¹è€…
```

### 5.3 å®¡æ ¸ä¸åˆå¹¶

#### 5.3.1 "Work in Progress" æ ‡è®°

**ç”¨é€”ï¼š** è¡¨æ˜ PR å°šæœªå®Œæˆ

```
PR æ ‡é¢˜æ·»åŠ å‰ç¼€ï¼š[WIP] Rename columns and add validations

å¾…å®Œæˆé¡¹ï¼š
- [ ] æ„å»ºé“¾æ¥
- [ ] æ•°æ®å¯¹æ¯”
- [ ] Contour åˆ†æ
```

å½“æ‰€æœ‰é¡¹å®Œæˆåï¼Œç§»é™¤ `[WIP]` æ ‡è®°å¹¶æ·»åŠ å®¡æ ¸è€…ã€‚

#### 5.3.2 å®¡æ ¸æƒé™é…ç½®

**å»ºè®®è®¾ç½®ï¼š**
1. è‡ªåŠ¨æ£€æŸ¥å¿…é¡»é€šè¿‡ï¼ˆChecks passingï¼‰
2. è‡³å°‘éœ€è¦ä¸€ç»„ç®¡ç†å‘˜æ‰¹å‡†
3. Master åˆ†æ”¯å—ä¿æŠ¤

### 5.4 åˆå¹¶åæ“ä½œ

#### 5.4.1 åœ¨ Master ä¸Šæ„å»º

```
PR åˆå¹¶
    â†“
ç­‰å¾… Master æ£€æŸ¥å®Œæˆ
    â†“
æ‰‹åŠ¨æ„å»ºæ•°æ®é›†
    æˆ–
ç­‰å¾…ä¸‹ä¸€æ¬¡é¢„å®š Schedule è¿è¡Œ
    â†“
éªŒè¯ç”Ÿäº§æ•°æ®
```

#### 5.4.2 Ontology åŒæ­¥

**å…³é”®ç‚¹ï¼š** å¯¹äºåŒæ­¥åˆ° Ontology çš„æ•°æ®é›†ï¼Œå¿…é¡»ç­‰å¾…åŒæ­¥å®Œæˆ

```
Master æ„å»ºå®Œæˆ
    â†“
Ontology åŒæ­¥ï¼ˆå¯èƒ½è€—æ—¶ï¼‰
    â†“
æ›´æ”¹åœ¨ä¸‹æ¸¸åº”ç”¨ä¸­ç”Ÿæ•ˆ
    - Object Explorer
    - Quiver
    - Workshop
```

### 5.5 PR æœ€ä½³å®è·µæ€»ç»“

**æ ¸å¿ƒåŸåˆ™ï¼š** æä¾›"è¯æ®"è€Œéä»…ä¾èµ–ä»£ç æ­£ç¡®æ€§

```
æœ‰æ•ˆçš„ PR = ä»£ç  + æ„å»ºè¯æ˜ + æ•°æ®å¯¹æ¯” + å…·ä½“åˆ†æ
```

**è¯„ä¼°æ ‡å‡†ï¼š**
| æ£€æŸ¥é¡¹ | ç›®çš„ | å½¢å¼ |
|-------|------|------|
| æ„å»ºé“¾æ¥ | è¯æ˜ä»£ç èƒ½ç¼–è¯‘è¿è¡Œ | æ„å»ºæˆåŠŸæˆªå›¾+ä¸‹æ¸¸éªŒè¯ |
| ç»“æ„å¯¹æ¯” | æ•°æ®æ•´ä½“å¥åº·åº¦ | Schema/è¡Œæ•°/ç©ºå€¼ç™¾åˆ†æ¯” |
| Contour åˆ†æ | å…·ä½“ä¸šåŠ¡é€»è¾‘æ­£ç¡® | ç‰¹å®šæ¡ˆä¾‹çš„æ•°æ®æ ·æœ¬å¯¹æ¯” |
| åç»­è¡ŒåŠ¨ | å®Œæ•´æ€§å’Œå½±å“èŒƒå›´ | æ¸…æ™°çš„åç»­ä»»åŠ¡åˆ—è¡¨ |

---

## å…­ã€å…³é”®æ ¸å¿ƒæ¦‚å¿µæ±‡æ€»

### 6.1 è£…é¥°å™¨æ¨¡å¼

| è£…é¥°å™¨ | ç”¨é€” | è¾“å…¥è¾“å‡º | è°ƒç”¨æ–¹å¼ |
|-------|------|---------|---------|
| `@transform_df` | å•è¾“å…¥/å•è¾“å‡º | è¡¨â†’è¡¨ | è‡ªåŠ¨å¤„ç† I/O |
| `@transform` | å¤šè¾“å…¥è¾“å‡º/æ–‡ä»¶å¤„ç† | æ–‡ä»¶â†’è¡¨/è¡¨â†’è¡¨ | æ˜¾å¼ I/O |
| `@incremental` | å¢é‡å¤„ç† | åŸå­åŒ– | é…åˆ semantic_version |

### 6.2 æ•°æ®è´¨é‡é˜²çº¿

```
æ•°æ®è¿›å…¥ Pipeline
    â†“
Input Expectations æ£€æŸ¥ï¼ˆéªŒè¯è¾“å…¥ï¼‰
    â†“
Transform æ‰§è¡Œï¼ˆæ•°æ®å¤„ç†ï¼‰
    â†“
Output Expectations æ£€æŸ¥ï¼ˆéªŒè¯è¾“å‡ºï¼‰
    â†“
å¤±è´¥ç­–ç•¥
    - Fail Buildï¼šé˜»æ­¢ä¸è‰¯æ•°æ®ä¼ æ’­
    - Warningï¼šä»…è®°å½•
    â†“
å®‰å…¨æ•°æ®è¿›å…¥ä¸‹æ¸¸ç³»ç»Ÿ
```

### 6.3 æ€§èƒ½ä¼˜åŒ–å±‚çº§

```
é¢„è§ˆé˜¶æ®µï¼ˆå¿«é€Ÿè¿­ä»£ï¼‰
    â”œâ”€ åŸºç¡€ Previewï¼ˆ10k è¡Œï¼‰
    â””â”€ è‡ªå®šä¹‰è¿‡æ»¤ï¼ˆç‰¹å®šæ¡ˆä¾‹ï¼‰

å¼€å‘é˜¶æ®µï¼ˆè°ƒè¯•ï¼‰
    â”œâ”€ æ–­ç‚¹è°ƒè¯•
    â”œâ”€ Console æµ‹è¯•
    â””â”€ å•å…ƒæµ‹è¯•

ç”Ÿäº§é˜¶æ®µï¼ˆå®Œæ•´éªŒè¯ï¼‰
    â”œâ”€ å…¨é‡æ„å»º
    â”œâ”€ å¢é‡æ„å»ºï¼ˆå·²ä¼˜åŒ–ï¼‰
    â””â”€ Schedule å®šæ—¶æ‰§è¡Œ
```

### 6.4 ä»£ç å¤ç”¨ä½“ç³»

```
æœ¬åœ°å‡½æ•°
    â””â”€ åœ¨ Module å†…å¤ç”¨

Python Library
    â”œâ”€ åˆ›å»º â†’ ç¼–å†™ â†’ å‘å¸ƒï¼ˆTagï¼‰
    â””â”€ åœ¨å…¶ä»–é¡¹ç›®å¯¼å…¥ä½¿ç”¨

é«˜çº§å¤ç”¨
    â””â”€ é€šè¿‡ Ontology å…±äº«æ•°æ®å®šä¹‰
```

---

## ä¸ƒã€å®è·µå»ºè®®ä¸å¸¸è§é™·é˜±

### 7.1 åå¤§å…³é”®è¦ç‚¹

1. **å§‹ç»ˆä¿æŠ¤ Master åˆ†æ”¯**
   - æ‰€æœ‰å¼€å‘åœ¨ç‹¬ç«‹åˆ†æ”¯è¿›è¡Œ
   - è®¾ç½®å®¡æ ¸äººç»„è€Œéå•äººå®¡æ ¸

2. **å……åˆ†åˆ©ç”¨ Preview å’Œè‡ªå®šä¹‰è¿‡æ»¤**
   - å¿«é€Ÿè¿­ä»£å¼€å‘
   - é’ˆå¯¹è¾¹ç•Œæƒ…å†µè°ƒè¯•

3. **å†™æ¸…æ¥šæäº¤ä¿¡æ¯å’Œ PR æè¿°**
   - ä¾¿äºæ—¥åä»£ç è€ƒå¤
   - å¸®åŠ©å®¡æ ¸è€…å¿«é€Ÿç†è§£

4. **æä¾›æ„å»ºå’Œæ•°æ®å¯¹æ¯”é“¾æ¥**
   - è¯æ˜ä»£ç å¯è¿è¡Œ
   - è¯æ˜æ•°æ®è´¨é‡æ­£å¸¸

5. **ä½¿ç”¨ Data Expectations ä½œä¸ºé˜²ç«å¢™**
   - åœ¨ç®¡é“å…¥å£æ£€æŸ¥æ•°æ®
   - å®å¯è¿‡æœŸä¹Ÿä¸è¦é”™è¯¯æ•°æ®

6. **æå–å¯æµ‹è¯•çš„çº¯å‡½æ•°**
   - åˆ†ç¦»è½¬æ¢é€»è¾‘ä¸ I/O
   - ä¾¿äºå•å…ƒæµ‹è¯•

7. **ä½¿ç”¨ RID è€Œéæ–‡ä»¶è·¯å¾„**
   - é¿å…è·¯å¾„æ–­è£‚
   - å‡å°‘å†²çª

8. **ä¼˜åŒ– Join å‰æ¸…ç†æ•°æ®**
   - å…ˆéªŒè¯è¿æ¥é”®å”¯ä¸€æ€§
   - é¿å…è¿æ¥çˆ†ç‚¸

9. **éµå¾ª"æ˜¾å¼ä¼˜äºéšå¼"åŸåˆ™**
   - æ˜ç¡® Join ç±»å‹
   - æ˜¾å¼æŒ‡å®š unionByName

10. **å…³æ³¨ä»£ç å¼‚å‘³**
    - é¿å…å°†æ•°æ®æ‹‰å› Driver
    - ä¸è¦ä½¿ç”¨è„†å¼±çš„ä¸»é”®æ„å»ºæ–¹å¼

### 7.2 å¸¸è§é™·é˜±ä¸è§£å†³æ–¹æ¡ˆ

| é™·é˜± | è¡¨ç° | è§£å†³æ–¹æ¡ˆ |
|------|------|---------|
| Join çˆ†ç‚¸ | è¾“å‡ºè¡Œæ•°è¿œè¶…é¢„æœŸ | Before Join éªŒè¯è¿æ¥é”®å”¯ä¸€æ€§ |
| ç©ºå€¼æ¿€å¢ | æ–°åˆ— NULL æ¯”ä¾‹è¿‡é«˜ | æ£€æŸ¥é€»è¾‘ï¼Œè€ƒè™‘ coalesce |
| å¢é‡å¤±æ•ˆ | é¢„æœŸå¢é‡å´å…¨é‡é‡ç®— | æ£€æŸ¥æ–‡ä»¶æ˜¯è¿½åŠ è¿˜æ˜¯æ›¿æ¢ |
| æ—§æ•°æ®æœªæ›´æ–° | æ–°åˆ—é€»è¾‘æœªåº”ç”¨åˆ°å†å²æ•°æ® | æå‡ semantic_version å¼ºåˆ¶å…¨é‡é‡ç®— |
| Python ç‰ˆæœ¬å†²çª | CI æ£€æŸ¥å¤±è´¥ | åœ¨ meta.yaml ä¸­è°ƒæ•´ç‰ˆæœ¬å…¼å®¹æ€§ |
| Lint è­¦å‘Š | ä»£ç æ£€æŸ¥ä¸é€šè¿‡ | ä½¿ç”¨ == æ¯”è¾ƒå­—ç¬¦ä¸²ï¼Œä¸ç”¨ is |
| Monocle æ„å»ºç”¨æ—§ä»£ç  | ä¿®æ”¹æœªç”Ÿæ•ˆ | ç­‰å¾… Master æ£€æŸ¥å®Œæˆå†åœ¨ Monocle æ„å»º |
| Library ä¸å‘å¸ƒ | æäº¤ä½†åº“ä»æ— æ³•ä½¿ç”¨ | åˆ›å»º Tag è§¦å‘å‘å¸ƒæµç¨‹ |

---

## å…«ã€æ¶æ„å¯¹æ ‡ä¸å‘å±•æ–¹å‘

### 8.1 ä¸å…¶ä»–æ•°æ®å¹³å°çš„å¯¹æ¯”

| ç‰¹æ€§ | Palantir Foundry | å…¶ä»–å¹³å° |
|------|-----------------|---------|
| ç¼–ç¨‹è¯­è¨€ | Python (PySpark) | SQL, Python, Scala |
| å¢é‡è®¡ç®— | åŸºäºæ–‡ä»¶äº‹åŠ¡ | åŸºäºåˆ†åŒºæˆ–æ—¶é—´æˆ³ |
| è´¨é‡ç®¡ç† | Data Expectations | Great Expectations, dbt tests |
| ä»£ç å¤ç”¨ | Python Library | Packages, Modules |
| ç‰ˆæœ¬ç®¡ç† | Git + RID | Git + File Paths |
| ç”Ÿäº§éƒ¨ç½² | Schedule + Manual | DAG + Scheduler |

### 8.2 æŠ€æœ¯æˆç†Ÿåº¦è¯„ä¼°

**å½“å‰é˜¶æ®µï¼š**
- âœ“ åŸºç¡€è½¬æ¢èƒ½åŠ›æˆç†Ÿ
- âœ“ å¢é‡è®¡ç®—æœºåˆ¶å¥å…¨
- âœ“ ä»£ç è´¨é‡å·¥å…·å®Œå–„
- âœ“ ç”Ÿäº§æµç¨‹è§„èŒƒåŒ–
- âœ“ æµ‹è¯•æ¡†æ¶é…å¥—

**æ¼”è¿›æ–¹å‘ï¼š**
- æ›´ç»†ç²’åº¦çš„å¢é‡æ§åˆ¶ï¼ˆè¡Œçº§ï¼‰
- AI è¾…åŠ©çš„ä»£ç å®¡æŸ¥
- æ›´æ™ºèƒ½çš„æ€§èƒ½ä¼˜åŒ–å»ºè®®
- è·¨é¡¹ç›®ä¾èµ–ç®¡ç†

---

## ä¹ã€å­¦ä¹ è·¯å¾„å»ºè®®

### åˆçº§å¼€å‘è€…è·¯å¾„

```
1. å­¦ä¹ å•è¾“å…¥/å•è¾“å‡ºè½¬æ¢ï¼ˆæ–‡æ¡£ 01ï¼‰
   â””â”€ ç›®æ ‡ï¼šæŒæ¡åŸºæœ¬çš„ @transform_df ä½¿ç”¨

2. å­¦ä¹ å•å…ƒæµ‹è¯•ï¼ˆæ–‡æ¡£ 03ï¼‰
   â””â”€ ç›®æ ‡ï¼šèƒ½ç¼–å†™å¯æµ‹è¯•çš„ä»£ç 

3. å­¦ä¹  Data Expectationsï¼ˆæ–‡æ¡£ 06ï¼‰
   â””â”€ ç›®æ ‡ï¼šå»ºç«‹æ•°æ®è´¨é‡æ„è¯†

4. å­¦ä¹ å¤šè¾“å…¥è¿æ¥ï¼ˆæ–‡æ¡£ 01 ä¸­çº§éƒ¨åˆ†ï¼‰
   â””â”€ ç›®æ ‡ï¼šå¤„ç†å¤æ‚ä¸šåŠ¡åœºæ™¯
```

### ä¸­çº§å¼€å‘è€…è·¯å¾„

```
1. å­¦ä¹ å¢é‡è®¡ç®—ï¼ˆæ–‡æ¡£ 02ï¼‰
   â””â”€ ç›®æ ‡ï¼šç†è§£æ€§èƒ½ä¼˜åŒ–æœºåˆ¶

2. å­¦ä¹ ä»£ç å¤ç”¨ä½“ç³»ï¼ˆæ–‡æ¡£ 04-05ï¼‰
   â””â”€ ç›®æ ‡ï¼šå¤§è§„æ¨¡é¡¹ç›®åä½œ

3. å­¦ä¹ ä»£ç å®¡æŸ¥æœ€ä½³å®è·µï¼ˆæ–‡æ¡£ 08ï¼‰
   â””â”€ ç›®æ ‡ï¼šæé«˜ä»£ç è´¨é‡

4. å­¦ä¹ å¼€å‘æµç¨‹ï¼ˆæ–‡æ¡£ 09ï¼‰
   â””â”€ ç›®æ ‡ï¼šå»ºç«‹å›¢é˜Ÿè§„èŒƒ
```

### é«˜çº§å¼€å‘è€…è·¯å¾„

```
1. å­¦ä¹ å¤æ‚æ•°æ®å¤„ç†ï¼ˆæ–‡æ¡£ 07ï¼‰
   â””â”€ ç›®æ ‡ï¼šå¤„ç†éç»“æ„åŒ–æ•°æ®

2. å­¦ä¹  PR ç®¡ç†æœ€ä½³å®è·µï¼ˆæ–‡æ¡£ 10ï¼‰
   â””â”€ ç›®æ ‡ï¼šè´Ÿè´£ä»£ç å®¡æ ¸

3. æ¶æ„è®¾è®¡ä¸æ€§èƒ½ä¼˜åŒ–
   â””â”€ ç›®æ ‡ï¼šè®¾è®¡å¤§è§„æ¨¡æ•°æ®ç®¡é“

4. å›¢é˜ŸåŸ¹è®­ä¸çŸ¥è¯†è½¬ç§»
   â””â”€ ç›®æ ‡ï¼šå»ºç«‹å›¢é˜ŸæŠ€æœ¯æ–‡åŒ–
```

---

## åã€æ€»ç»“ä¸å»ºè®®

### 10.1 æ ¸å¿ƒä»·å€¼ä¸»å¼ 

Palantir Foundry Code Repositories æä¾›äº†ä¸€ä¸ª**ä»ä»£ç åˆ°ç”Ÿäº§çš„å®Œæ•´é—­ç¯**ï¼š

```
å¼€å‘â†’æµ‹è¯•â†’å®¡æŸ¥â†’å‘å¸ƒâ†’ç›‘æ§
 â†‘                          â†“
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      (åé¦ˆä¸æŒç»­ä¼˜åŒ–)
```

### 10.2 ä¸‰å¤§æˆåŠŸå› ç´ 

1. **ä»£ç è´¨é‡ç¬¬ä¸€**
   - æ¸…æ™°çš„ä»£ç è§„èŒƒ
   - å®Œå–„çš„ Linter é˜²æŠ¤
   - å¼ºåˆ¶çš„ä»£ç å®¡æŸ¥

2. **æ•°æ®è´¨é‡é˜²çº¿**
   - è¾“å…¥/è¾“å‡ºæœŸæœ›æ£€æŸ¥
   - æ„å»ºå‰æ•°æ®éªŒè¯
   - å¤±è´¥æ—¶åŠæ—¶é˜»æ­¢

3. **ç”Ÿäº§ç¨³å®šæ€§ä¿éšœ**
   - Master åˆ†æ”¯ä¿æŠ¤
   - å®Œæ•´çš„ PR æµç¨‹
   - äº‹åéªŒè¯ä¸åŒæ­¥

### 10.3 ç»„ç»‡å»ºè®®

**å¯¹æ•°æ®å·¥ç¨‹å›¢é˜Ÿï¼š**
1. å»ºç«‹å›¢é˜Ÿçš„å¼€å‘è§„èŒƒï¼ˆåŸºäºæ–‡æ¡£ 08-09ï¼‰
2. å¼ºåˆ¶æ‰§è¡Œ Code Reviewï¼ˆåŸºäºæ–‡æ¡£ 10ï¼‰
3. å®šæœŸå®¡è§†å¢é‡æ„å»ºé…ç½®ï¼ˆåŸºäºæ–‡æ¡£ 02ï¼‰
4. ç›‘æ§ Data Expectations å¤±è´¥ç‡

**å¯¹äº§å“å¼€å‘å›¢é˜Ÿï¼š**
1. å……åˆ†åˆ©ç”¨ Data Expectations ç¡®ä¿æ•°æ®è´¨é‡
2. ä½¿ç”¨ RID æ›¿ä»£è·¯å¾„å¢å¼ºç¨³å¥æ€§
3. æŠ•èµ„å•å…ƒæµ‹è¯•æé«˜é•¿æœŸå¯ç»´æŠ¤æ€§

**å¯¹ç®¡ç†å±‚ï¼š**
1. ç¡®ä¿ Master åˆ†æ”¯ä¿æŠ¤æœºåˆ¶åˆ°ä½
2. å»ºç«‹å®¡æ ¸æƒé™çš„äºŒçº§åˆ¶è¡¡
3. å®šæœŸè¯„ä¼°ä»£ç è´¨é‡æŒ‡æ ‡

### 10.4 æœ€åçš„å»ºè®®

> **"åªæœ‰ç»ƒä¹ æ‰èƒ½é€ å°±å®Œç¾"** â€”â€” Palantir Developers

Code Repositories çš„å­¦ä¹ ä¸ä»…æ˜¯æŠ€æœ¯çš„å­¦ä¹ ï¼Œæ›´æ˜¯**å·¥ç¨‹æ–‡åŒ–**çš„å»ºç«‹ã€‚å»ºè®®ï¼š

1. **ä»å°å¤„å¼€å§‹** - åœ¨ä¸ªäººé¡¹ç›®ä¸­å®è·µ
2. **ä»£ç å®¡æŸ¥** - ä¸å›¢é˜Ÿåˆ†äº«å’Œè®¨è®º
3. **æŒç»­æ”¹è¿›** - å®šæœŸå›é¡¾å’Œä¼˜åŒ–
4. **çŸ¥è¯†æ²‰æ·€** - å°†ç»éªŒæ•´ç†æˆå›¢é˜ŸæŒ‡å—

---

## é™„å½•ï¼šå¿«é€Ÿå‚è€ƒè¡¨

### é™„è¡¨ Aï¼šè£…é¥°å™¨é€ŸæŸ¥

```python
# å•è¾“å…¥/å•è¾“å‡º
@transform_df
def process(flights_df):
    return flights_df.filter(col("distance") > 100)

# å¤šè¾“å…¥
@transform_df(flights=inputs.flights, carriers=inputs.carriers)
def process(flights_df, carriers_df):
    return flights_df.join(carriers_df, "carrier_code")

# å¤šè¾“å‡º
@transform
def split_data(ctx, output1, output2):
    df = ctx.run_input.flights.dataframe()
    output1.write_dataframe(df.filter(col("distance") < 500))
    output2.write_dataframe(df.filter(col("distance") >= 500))

# å¢é‡å¤„ç†
@incremental(semantic_version="1")
def incremental_transform(ctx, input_data, output):
    pass
```

### é™„è¡¨ Bï¼šå¸¸ç”¨æ£€æŸ¥æ¨¡å¼

```python
from foundry.data_expectations import *

# é€»è¾‘æ£€æŸ¥
check(departure).is_before(arrival)

# æ ¼å¼æ£€æŸ¥
check(airport_code).rlike("^[A-Z]{3}$")

# èŒƒå›´æ£€æŸ¥
check(distance).is_between(0, 10000)

# éç©ºæ£€æŸ¥
check(flight_id).is_not_null()

# å”¯ä¸€æ€§æ£€æŸ¥
check(flight_id).is_unique()
```

### é™„è¡¨ Cï¼šå¸¸ç”¨ PySpark æ¨¡å¼

```python
# æ¸…ç†å Join
df_cleaned = (input_df
    .select("id", "carrier_code")
    .dropDuplicates())

result = (df_cleaned
    .join(carriers, "carrier_code", "inner")
    .select("df_cleaned.*", "carriers.name"))

# ä½¿ç”¨è‡ªç„¶è¿æ¥
result = (flights
    .withColumnRenamed("carrier_id", "code")
    .join(carriers.withColumnRenamed("id", "code"), "code"))

# Broadcast ä¼˜åŒ–
result = flights.join(carriers.hint("broadcast"), "carrier_code")

# å®‰å…¨çš„ä¸»é”®
df = df.withColumn("pk",
    when(col("id").isNotNull() & col("date").isNotNull(),
         concat_ws("-", col("id"), col("date")))
    .otherwise(col("id")))
```

---

**æŠ¥å‘Šç”Ÿæˆæ—¥æœŸï¼š** 2026 å¹´ 1 æœˆ

**æ–‡æ¡£ç‰ˆæœ¬ï¼š** 1.0

**æ¨èç‰ˆæœ¬ï¼š** å»ºè®®åœ¨ Palantir Foundry 2025 Q4+ ç¯å¢ƒä¸­å‚è€ƒåº”ç”¨

