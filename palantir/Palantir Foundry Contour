Palantir Foundry Contour： 是一款专为**大规模数据集（Datasets）**设计的低代码/无代码分析应用程序 [1, 2]。在 Foundry 的分析工具矩阵中，Contour 与 Quiver 有着明确的分工：如果分析对象是本体（Ontology）中的**对象或时间序列**，应使用 Quiver；如果直接对**原始数据集**进行大规模分析，则 Contour 是首选工具 [3, 4]。
以下是关于 Contour 101 的核心概念、操作流程及高级功能的详细介绍：
### 1. 核心架构：分析路径（Paths）与卡板（Boards）
Contour 的分析逻辑建立在**路径（Path）**和**卡板（Board）**的基础之上：
*   **分析路径 (Path)：** 类似于 Excel 中的工作表，是组织分析逻辑的块 [5]。每个 Contour 分析可以包含多个路径，路径之间可以相互引用，例如从一个路径的末端启动新路径 [6]。
*   **卡板 (Board)：** 卡板是路径中的最小指令单位，其功能只有两种：**展示数据**（如表格、图表）或**转换数据**（如过滤、联接、聚合） [7, 8]。
*   **持久化存储：** 与某些临时查询工具不同，Contour 中的所有操作都会自动保存为文件，不存在瞬时或不保存的查询 [9]。

### 2. 基础操作工作流
在 Contour 中进行分析通常遵循以下步骤：
*   **启动分析：** 用户可以通过应用门户进入，或者直接在数据集预览界面点击“Analyze in Contour”按钮开始 [1, 10]。
*   **添加数据：** 所有分析路径都必须以一个数据集作为起点 [11]。
*   **数据预览：** 界面右侧（或底部）设有“显示数据（Show Data）”面板，允许用户在不添加额外卡板的情况下，实时查看当前步骤的数据形态 [12]。
*   **转换操作：**
    *   **过滤 (Filter)：** 可以根据文本、日期或数值筛选行，支持“匹配所有”或“匹配任一”逻辑，并能处理空值（Null） [8, 13]。
    *   **联接 (Join/Add Columns)：** 允许通过关联键（如 Store ID）从其他数据集中引入新列，支持左联接、右联接、内联接等常见模式 [14, 15]。
    *   **聚合与透视 (Pivot Table)：** 支持创建复杂的透视表进行指标汇总（如求和、计数），并提供**“切换至透视数据（Switch to pivoted data）”**功能，使下游所有卡板都基于透视后的结构运行 [16, 17]。

### 3. 可视化与图表应用
Contour 提供了丰富的图表卡板（Chart Board）来增强数据感知：
*   **多维展示：** 用户可以配置 X 轴（如按月分组的时间戳）和 Y 轴（如销售额总和），并支持通过字段（如连锁店名称）进行**细分（Segment by）**，生成分色显示的堆叠图或对比图 [18-20]。
*   **快速复制：** 如果需要创建配置相似的图表，可以利用“复制”和“粘贴卡板”功能来节省重新配置的时间 [20, 21]。

### 4. 交互性与仪表盘（Dashboards）
Contool 不仅仅是静态分析工具，它还具备构建**自服务式分析产品**的能力：
*   **参数化 (Parameters)：** 类似于编程中的变量，用户可以定义字符串、日期或数字参数，并将其绑定到过滤卡板中 [22-24]。
*   **仪表盘构建：** 用户可以将特定的图表或透视表“添加至仪表盘”，并通过拖拽调整布局（如并排显示） [25, 26]。
*   **分享与协作：** 仪表盘支持通过链接分享，且链接可以包含**预填的参数值**，使接收者打开即见特定视角的数据 [27, 28]。
*   **查看与编辑模式：** 平台区分编辑权限和查看权限。仅拥有查看权限的用户可以使用参数进行交互，但无法修改分析路径的逻辑 [28, 29]。

### 5. 数据更新机制
Contour 能够处理动态变化的数据流。用户可以配置**“打开时刷新分析数据（Refresh analysis data on open）”**，确保每次打开仪表盘时，系统都会自动检查底层数据集是否有更新，并重新计算所有卡板的结果 [29, 30]。
2. Foundry Pipeline Builder
**Foundry Pipeline Builder** 是 Palantir Foundry 中用于构建生产级数据管道的**无代码（No-code）环境** [1, 2]。它旨在让非编程人员也能创建高性能、具备版本控制能力并深度集成于 Foundry 数据工程生态系统的工作流 [1]。

以下是关于 Pipeline Builder 的详细技术介绍：

### 1. 核心架构与管道类型
Pipeline Builder 将复杂的编码逻辑抽象为直观的**图形化画布（Canvas）**，其中节点代表数据集，方框代表转换操作 [3]。它支持两种主要的管道模式：
*   **批处理管道（Batch Pipelines）：** 适用于按预设计划（如每五分钟或每天一次）摄取的数据 [4]。
*   **流处理管道（Streaming Pipelines）：** 专门用于实时数据处理 [1, 5]。

### 2. 主要功能与转换操作
在管道构建过程中，用户可以执行从基础到高级的各类数据清洗和转换任务：
*   **基础转换：** 包括**类型转换（Cast）**（例如将字符串转换为时间戳）、**过滤行（Filter）**（剔除空值或无效数据）、**删除列（Drop）**以及**规范化列名** [6-9]。
*   **数据整合：** 支持多种类型的**联接（Join）**（如左联接、右联接、内联接及地理空间联接）和**联合（Union）**操作，将分散的数据源合并为统一的实体 [10-12]。
*   **解析与抽取：** 能够直接从 **Excel 工作簿**中提取特定工作表的数据，并支持使用**正则表达式（Regex）**进行复杂的文本处理 [13, 14]。

### 3. AIP（人工智能平台）集成
Pipeline Builder 深度集成了 Palantir 的 **AIP 能力**，极大简化了开发过程：
*   **自动逻辑说明：** AIP 可以为画布上的特定节点生成解释，帮助新成员快速理解管道逻辑 [15]。
*   **智能命名：** AIP 能根据转换逻辑建议合适的步骤名称（如“计算税额与总计”） [16]。
*   **辅助生成：** 用户只需描述需求，AIP 即可辅助生成正则表达式，例如“添加前导零以符合五位邮编格式” [17]。

### 4. 复用性与参数化（Reusables）
为了提高管道的维护效率，Pipeline Builder 提供了两类复用机制：
*   **参数（Parameters）：** 允许用户定义变量（如“税率”），在多个转换步骤中引用。若需修改逻辑，只需在一处更改参数值即可 [18]。
*   **自定义转换函数（Custom Functions）：** 用户可以将一系列转换逻辑封装为一个自定义函数（如“增加前导零”函数），使其像内置功能一样在管道中多次调用 [19, 20]。

### 5. 版本控制与协作管理
Pipeline Builder 引入了类似于软件工程的 **Git 版本控制语义**，以确保生产环境的安全：
*   **分支（Branching）：** 开发者可以在独立的分支（沙盒环境）中进行修改，而不影响主分支（Main）或生产流 [21, 22]。
*   **提案（Proposals）：** 类似于 GitHub 的 Pull Request，修改完成后需创建提案供同事审核。审核者可以通过**“变更视图”**直观对比主分支与分支之间的图形逻辑差异 [22, 23]。

### 6. 部署与执行逻辑
理解 Pipeline Builder 的操作逻辑需区分**“保存”**与**“部署”**：
*   **保存（Saving）：** 仅保存文件草稿，供后续编辑 [24]。
*   **部署（Deploying）：** 更新数据的**作业规范（Job Spec）**。只有部署后，Foundry 才会根据最新的管道逻辑来构建和填充目标数据集 [24-26]。通过 **Job Tracker**（也称 Builds 应用），用户可以实时监控部署后的构建进度和健康状态 [25, 27]。

### 7. 与其他工具的对比
*   **对比 Contour：** Pipeline Builder 用于构建从原始数据到清洗后数据集的**生产管道**；而 Contour 侧重于对已有数据集进行点选式**分析与仪表盘展示** [28, 29]。
*   **对比代码库（Code Repositories）：** Pipeline Builder 提供无代码体验，而代码库则允许使用 **Python (PySpark)** 进行更加灵活、基于代码的深度开发 [30, 31]。
