在 Palantir Foundry 中，通过 **Webhooks** 与 HuggingFace 交互是一种非常有效的技术，它允许用户在面向用户的应用程序（如 Workshop）中直接与机器学习模型进行实时交互 [1]。

以下是基于源代码的详细操作指南：

### 1. 前期准备
在开始配置之前，需要完成以下准备工作：
*   **选择模型：** 从 HuggingFace 选定一个模型（例如 `whisper-large-v3` 音频转文字模型） [1]。
*   **API 类型：** 确保该模型可以通过**无服务器（Serverless）推理 API（Inference API）**进行部署 [1]。
*   **访问令牌：** 获取一个 HuggingFace 的 **Read Token** 用于身份验证 [1]。

### 2. 配置数据源 (Data Connection)
首先，需要在 Data Connection 应用程序中定义与 HuggingFace API 的交互方式：
*   **创建源 (Source)：** 选择 **REST API** 类型并进行直接连接 [2]。
*   **基本 URL (Base URL)：** 输入从 HuggingFace 模型页面获取的推理 API URL [3]。
*   **身份验证：** 使用 **Bearer Token** 模式，并填入你的 HuggingFace Token [3]。
*   **网络出口策略 (Egress Policy)：** 必须选择或申请一条允许流量访问 HuggingFace 域名的出口策略 [3]。

### 3. 创建 Webhook
在配置好的数据源下创建一个新的 Webhook：
*   **请求方法：** 将方法从 GET 修改为 **POST** [4]。
*   **路径：** 填入特定模型的 URL 后缀 [4]。
*   **输入参数：** 添加一个参数（例如名为 `inputs`），其类型设置为 **Attachment（附件）**（适用于音频或文件输入） [4]。
*   **请求体 (Body)：** 在 Body 设置中选择文件附件，并将其映射到刚才定义的 `inputs` 参数 [4]。
*   **响应定义：** 配置如何解析返回的数据。由于响应通常是结构化的，可以使用 **"Extract by key"** 功能（例如提取键名为 `text` 的内容）来直接获取字符串形式的预测结果 [5]。

### 4. 本体与操作设置 (Ontology & Actions)
为了存储和展示模型的预测结果，需要建立相应的本体结构：
*   **创建对象类型：** 创建一个新的对象类型（如 `HuggingFace Response`）来持有响应数据。包含属性：`Response` (String)、`Submitted By` 和 `Submitted At` (Timestamp) [6]。
*   **启用编辑：** 确保该对象类型已开启 **"Allow Edits"**，以便通过操作写入数据 [6]。
*   **创建操作类型 (Action Type)：** 
    *   创建一个基于 Webhook 的操作类型 [7]。
    *   **定义规则：** 添加一条 **"Create Object"** 规则。将 Webhook 的返回结果（Writeback Response）映射到对象的 `Response` 属性，并将当前时间和当前用户分别映射到对应的元数据属性中 [8]。

### 5. 应用程序集成 (Workshop)
最后，在 Workshop 中构建用户界面：
*   **上传组件：** 添加一个按钮组（Button Group）用于上传文件并触发操作 [9]。
*   **展示结果：** 使用 **对象列表 (Object List)** 窗口展示结果。建议按 `Submitted At` 时间戳降序排列，以便用户能立即在列表顶部看到最新的识别结果 [10]。

### 总结流程
整个端到端的工作流为：**创建 HuggingFace 数据源 -> 配置 Webhook -> 定义本体对象 -> 创建集成 Webhook 的 Action -> 在 Workshop 中调用并展示结果** [9]。这种方法实现了从原始音频（附件）到云端模型处理，再到 Foundry 本体数据持久化的全过程。
