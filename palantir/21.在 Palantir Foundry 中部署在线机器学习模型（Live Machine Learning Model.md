在 Palantir Foundry 中部署**在线机器学习模型（Live Machine Learning Model）**的主要目的是让终端用户能够在 Workshop 等应用程序中实时与模型交互，并根据输入的变化获取即时预测结果 [1, 2]。

以下是部署在线模型并将其集成到应用程序中的详细流程：

### 1. 模型准备与启动部署
*   **训练模型：** 在开始部署之前，必须首先在代码仓库（Code Repositories）或工作区中训练好一个模型（例如单车需求预测模型）[3, 4]。
*   **启动在线部署：** 进入模型资源页面，点击 **“Start deployment”** 按钮启动部署服务 [5, 6]。一旦状态显示为“正在运行（Running）”，该在线部署即可使用 [5, 6]。
*   **封装为函数：** 为了让 Workshop 等应用能够调用该模型，需要将模型版本**包装在一个函数（Function）中并发布** [5, 6]。发布时通常建议开启行处理（Row processing）模式 [5, 6]。

### 2. 本体（Ontology）建模
*   **创建对象类型：** 为了将数据喂给模型，本体中需要有一个对应的**对象类型**来代表模型输入的实例（例如“单车租赁观察”对象） [7, 8]。
*   **属性映射：** 确保该对象类型的属性涵盖了模型所需的所有特征（Features），如温度、湿度、风速等 [9-12]。

### 3. 在 Workshop 中集成模型
*   **配置输入变量：** 
    *   在 Workshop 中使用**对象列表（Object List）**组件供用户选择特定的数据记录 [13, 14]。
    *   创建一系列数字（Numeric）和字符串（String）变量，通过 **“对象属性（Object Property）”** 备份，从用户选中的记录中提取特征值 [10, 12, 15, 16]。
*   **调用模型函数：** 
    *   由于在线模型返回的是结构化数据，需要创建一个 **“由函数支持的结构体变量（Function-backed struct variable）”** [17, 18]。
    *   在该变量的设置中选择之前发布的模型函数，并将准备好的特征变量映射到函数的输入参数中 [10, 12, 17, 18]。
*   **提取预测结果：** 
    *   模型输出是一个结构体，需创建一个 **“结构体字段（Struct field）”** 变量，专门从中提取名为 `prediction` 的预测值字段 [19, 20]。
    *   使用 **Markdown 文本框**等组件展示最终的预测消息。可以通过变量转换（Variable Transformation）将预测数值拼接成用户易读的文本（如“当日预测需求为：5500 辆”） [21, 22]。

### 4. 实现实时交互与假设分析（What-if Analysis）
*   **动态修改输入：** 在应用中添加**数字输入框（Numeric Input）**，允许用户修改模型特征 [23, 24]。
*   **响应式更新：** 将输入框的默认值设置为对象属性变量，但允许用户手动覆盖。当用户在应用前端修改风速或温度等数值时，底层的函数变量会重新计算并**实时更新预测结果** [21, 22, 25, 26]。
*   **业务洞察：** 这种部署方式允许用户直观地看到变量变化对业务指标的影响（例如：风速从 11mph 增加到 30mph 时，预测的单车需求会显著下降） [27, 28]。

通过这种方式，Foundry 将静态的机器学习模型转化为**交互式的决策支持工具**，并完整保留了数据到决策的生产链条 [1, 2, 27, 28]。
