在 Palantir Foundry 中构建**视觉语义搜索（Visual Semantic Search）**应用，是通过多模态大模型将图像内容转化为文本描述，再利用向量嵌入（Embeddings）技术实现基于“意义”而非“关键词”的图像检索。 [1]

以下是根据来源整理的详细实施步骤：

### 1. 数据准备与媒体集上传
*   **创建媒体集：** 将图像文件（如宠物照片或工业零件图）上传至 Foundry，并选择存为**媒体集（Media Set）**。 [2] 媒体集是平台存储非结构化数据的核心方式，能够生成一个特殊的指针——**媒体引用（Media Reference）**，用于在后续流程中引用图像而无需重复存储。 [3, 4]
*   **创建项目文件夹：** 建议为视觉语义搜索项目创建专门的文件夹，以统一管理 Pipeline Builder 管道、本体对象和 Workshop 应用。 [2, 5]

### 2. 在 Pipeline Builder 中生成图像描述
*   **摄取数据：** 在管道中添加上述媒体集作为输入数据。 [6]
*   **应用多模态模型（Use LLM）：** 使用 **Use LLM** 转换插件，选择 GPT-4o 等多模态模型。 [3, 7]
*   **提示词工程：** 对图像的 **media reference** 列进行处理。 [7] 建议编写一个详细的系统提示词，要求模型用几句话描述图像内容（例如包含主体、环境和 demeanor/表达方式），输出列命名为 `image description`。 [3, 8]
*   **效果：** 模型会将图像转化为富文本描述，例如“一只带有黑色花纹的白猫坐在棕色纸箱里”。 [8]

### 3. 计算向量嵌入与本体建模
*   **文本转向量：** 在生成的图像描述后添加 **Text to embedding** 转换，选择一个嵌入模型（如 `text-embedding-3-small` 或 `ADA 2`），输出列命名为 `embedding`。 [9, 10]
*   **定义对象类型：** 直接从 Pipeline Builder 添加输出，创建一个新的**对象类型（Object Type）**（例如 `pet_image`）。 [9]
*   **配置关键属性：** 
    *   将 **Media Item RID** 设置为主键（Primary Key），以确保唯一性。 [11]
    *   将图像描述设置为标题键（Title Key）。 [11]
    *   确保本体管理器正确识别 `embedding` 为向量类型，并关联相应的嵌入模型。 [10, 11]

### 4. 在 Workshop 中构建搜索应用
*   **添加搜索框：** 在 Workshop 应用的顶部添加一个 **Text Input（文本输入）** 组件，供用户输入查询词（如“纸箱里的猫”）。 [12]
*   **配置语义过滤：** 
    *   创建一个对象集变量（Object Set），起始于之前创建的图像对象类型。 [13]
    *   在该对象集上应用过滤器，选择**嵌入属性（Embedding property）**。 [13]
    *   系统会自动启用 **K-最近邻 (kNN) 搜索**。将查询值绑定到文本输入组件的输出，并设置返回结果的数量（K 值，如 3 或 5）。 [13, 14]
*   **视觉化展示：** 
    *   添加 **Object List（对象列表）** 组件展示搜索结果。 [15]
    *   配置列表以**网格（Grid）**模式显示。 [15]
    *   关键点在于添加 **Media Reference** 属性，Workshop 会自动将其渲染为对应的图像预览。 [15]

### 5. 核心优势
这种视觉语义搜索不依赖于文件名或人工标签。 [16] 即使图像描述中从未出现过某个具体词汇，只要用户的查询在语义空间中与描述接近（例如搜索“短腿狗”时返回柯基的照片），系统就能精准召回最相关的视觉结果。 [16, 17] 这一流程在制造业维护（识别故障零件照片）或进度监控等实际业务场景中具有很高的应用价值。 [17]
