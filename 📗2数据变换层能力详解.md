# 📗 数据变换层能力详解 - ETL与数据工程

> **无代码到生产级的数据转换** - Pipeline Builder × SQL表达式 × Code Repositories

**对应工具编号**：02.Pipeline Builder、04.SQL表达式、05.Code Repositories
**适合角色**：数据工程师、数据架构师、BI开发者
**学习周期**：5-10天

---

## 📑 目录

1. [第1章：核心概念与架构](#第1章-核心概念与架构)
2. [第2章：Pipeline Builder - 可视化 ETL](#第2章-pipeline-builder---可视化etl)
3. [第3章：SQL 表达式 - 高阶查询](#第3章-sql-表达式---高阶查询)
4. [第4章：Code Repositories - 生产级开发](#第4章-code-repositories---生产级开发)
5. [性能优化指南](#性能优化指南)
6. [最佳实践与避坑](#最佳实践与避坑)

---

## 第1章：核心概念与架构

### 1.1 数据变换层的定位

```
本体数据层（原始业务对象）
    ↓
数据变换层（清洗、转换、聚合）
    ↓ 输出：清洁数据集、派生指标
分析层（Contour、Quiver）
    ↓
应用层（Workshop、Notepad）
    ↓
AI层（AIP Logic、AIP Agents）
```

### 1.2 三种变换工具对比

| 维度 | Pipeline Builder | SQL 表达式 | Code Repositories |
|------|-----------------|-----------|------------------|
| **界面** | 可视化拖拖拽拽 | SQL 编辑器 | Python/PySpark IDE |
| **学习曲线** | 最低（非技术人员可用） | 中等（需 SQL 基础） | 最高（需编程能力） |
| **灵活性** | 中（内置转换组件） | 高（完整 SQL 能力） | 最高（编程完全控制） |
| **性能** | 好（自动优化） | 好（Spark SQL 优化） | 最好（可手工优化） |
| **版本控制** | Git 集成 | 有限 | 完整（专业 Git）|
| **适用场景** | 标准 ETL 流程 | 复杂业务逻辑 | 生产系统、ML|
| **团队** | 分析师、BA | 数据工程师 | 数据科学家|

---

## 第2章：Pipeline Builder - 可视化 ETL

### 2.1 核心概念

**Pipeline Builder** 是 Foundry 的可视化 ETL 工具，核心流程：

```
数据源 → 转换节点（Filter/Join/Aggregate） → 输出

特点：
├─ 无代码设计
├─ Git 自动版本控制（所有 Pipeline 代码自动存储）
├─ 参数化支持（可复用）
├─ 实时监控与告警
└─ 与本体自动集成
```

### 2.2 Pipeline 的基本结构

```
┌─────────────────────────────────────────────────┐
│ Pipeline: order_processing (v2.3)              │
├─────────────────────────────────────────────────┤
│                                                 │
│ ┌────────────┐                                 │
│ │ ORDERS     │ ── 5.2M rows                   │
│ │ (Input)    │                                │
│ └────┬───────┘                                 │
│      │                                          │
│      ▼                                          │
│ ┌────────────────────┐                        │
│ │ Filter             │ WHERE amount > 0        │
│ │ order_amount > 0   │     AND status NOT NULL │
│ └────┬───────────────┘                        │
│      │                                          │
│      ▼ (5.15M rows 经过过滤)                   │
│ ┌─────────────────────┐                       │
│ │ Join Customers      │                        │
│ │ ON customer_id      │                        │
│ └────┬────────────────┘                       │
│      │                                          │
│      ▼ (added: name, region, segment)          │
│ ┌──────────────────────┐                      │
│ │ Aggregate            │                       │
│ │ GROUP BY region      │ SUM, COUNT, AVG      │
│ │ ORDER BY            │                       │
│ └────┬─────────────────┘                      │
│      │                                          │
│      ▼ (365 rows - 1 row per day per region)   │
│ ┌──────────────────────┐                      │
│ │ Output               │                       │
│ │ orders_final         │                       │
│ └──────────────────────┘                      │
└─────────────────────────────────────────────────┘

性能指标：
├─ 总耗时：2 分 30 秒
├─ 输入行数：5.2M
├─ 输出行数：365
├─ 压缩比：14,212:1
└─ 状态：✅ 成功
```

### 2.3 核心转换组件详解

#### 组件1：Filter（过滤）

```
用途：行级过滤，删除不符合条件的行

【UI操作】
├─ 1. 拖入 "Filter" 组件
├─ 2. 连接上游数据源
├─ 3. 配置过滤条件：
│  ├─ Condition 1：order_amount > 0
│  │  └─ 类型：Number comparison
│  ├─ AND Condition 2：status IN ('CONFIRMED', 'SHIPPED', 'DELIVERED')
│  │  └─ 类型：String list
│  ├─ AND Condition 3：customer_id IS NOT NULL
│  │  └─ 类型：Null check
│  └─ AND Condition 4：DATEDIFF(order_date, NOW()) <= 365
│     └─ 类型：Date range
└─ 4. 预览结果（显示过滤前后行数）

【示例条件】
过滤条件表达式：
WHERE order_amount > 0
  AND status NOT IN ('CANCELLED', 'PENDING')
  AND customer_id IS NOT NULL
  AND order_date >= DATE_SUB(TODAY(), INTERVAL 1 YEAR)

结果：
├─ 输入：1,000,000 行
├─ 输出：850,000 行
├─ 过滤率：85%（留下）
└─ 删除：150,000 行（不符合条件）

【常见用途】
1. 数据质量检查
   └─ 删除 NULL、重复、异常值
2. 业务过滤
   └─ 仅保留"完成"的订单
3. 时间范围
   └─ 仅保留过去 12 个月的数据
4. 数据隐私
   └─ 删除包含敏感信息的行
```

#### 组件2：Join（联接）

```
用途：将多个数据源关联

【UI操作】
├─ 1. 拖入 "Join" 组件
├─ 2. 连接两个输入源：
│  ├─ 左表：ORDERS（5M 行）
│  └─ 右表：CUSTOMERS（100K 行）
├─ 3. 选择 Join 类型：
│  ├─ INNER JOIN：仅保留两表都有的行
│  ├─ LEFT JOIN：保留左表所有行（推荐用于事实表+维度表）
│  ├─ RIGHT JOIN：保留右表所有行
│  └─ FULL OUTER JOIN：保留两表所有行
├─ 4. 配置 Join 键：
│  ├─ Left Key：ORDERS.customer_id
│  ├─ Right Key：CUSTOMERS.customer_id
│  ├─ 等值条件：=
│  └─ 可选：多个 Key（Order.customer_id AND Order.store_id）
├─ 5. 选择输出字段：
│  ├─ 从左表：order_id, order_date, amount, status
│  ├─ 从右表：customer_name, region, segment, email
│  └─ 去重：自动去除重复列（如 customer_id）
└─ 6. 处理不匹配行：
   ├─ 保留为 NULL
   └─ 或用默认值填充

【性能考虑】
广播 Join（右表较小）：
├─ 条件：右表 <100MB
├─ 优点：性能最好
├─ 自动：Foundry 自动检测并使用

Shuffle Join（两表都大）：
├─ 条件：左表 > 1GB 且右表 > 1GB
├─ 注意：可能内存溢出
├─ 优化：在 Join 前对右表 DISTINCT
└─ 示例：
    RIGHT TABLE(DISTINCT customer_id, ...) ← 先去重
    ↓
    JOIN LEFT TABLE
    └─ 减少右表大小，提高性能

【常见用途】
1. 维度表关联
   ├─ ORDERS ⟵ CUSTOMERS（获取客户信息）
   ├─ ORDERS ⟵ PRODUCTS（获取产品信息）
   └─ ORDERS ⟵ STORES（获取门店信息）
2. 多源数据融合
   ├─ 交易数据 ⟵ 客户数据 ⟵ 市场数据
3. 数据丰富化
   └─ 原始数据 + 计算字段 + 分类标签
```

#### 组件3：Aggregate（聚合）

```
用途：分组和统计汇总

【UI操作】
├─ 1. 拖入 "Aggregate" 组件
├─ 2. 配置分组维度：
│  ├─ GROUP BY region：按地区分组
│  ├─ GROUP BY order_date：按订单日期分组
│  └─ 多维：GROUP BY region, order_month
├─ 3. 配置聚合指标：
│  ├─ COUNT(*) as order_count
│  ├─ SUM(amount) as total_revenue
│  ├─ AVG(amount) as avg_order_value
│  ├─ MIN(amount), MAX(amount)
│  ├─ COUNT(DISTINCT customer_id) as unique_customers
│  └─ STDDEV(amount) as revenue_stddev
├─ 4. 可选：排序和限制
│  ├─ ORDER BY total_revenue DESC
│  └─ LIMIT 10（仅保留前 10）
└─ 5. 预览结果

【示例】
输入数据：
┌────────┬────────┬─────────┐
│ region │ order_ │ amount  │
│        │ date   │         │
├────────┼────────┼─────────┤
│ 北区   │ 01-01  │ 10,000  │
│ 北区   │ 01-01  │ 8,000   │
│ 北区   │ 01-02  │ 12,000  │
│ 南区   │ 01-01  │ 15,000  │
│ 南区   │ 01-01  │ 9,000   │
└────────┴────────┴─────────┘

聚合条件：GROUP BY region, order_date

输出结果：
┌────────┬────────┬─────────┬──────────────┬────────────┐
│ region │ date   │ count   │ total_rev    │ avg_order  │
├────────┼────────┼─────────┼──────────────┼────────────┤
│ 北区   │ 01-01  │ 2       │ 18,000       │ 9,000      │
│ 北区   │ 01-02  │ 1       │ 12,000       │ 12,000     │
│ 南区   │ 01-01  │ 2       │ 24,000       │ 12,000     │
└────────┴────────┴─────────┴──────────────┴────────────┘

【窗口函数示例】
高级聚合：计算排名、累积和、环比增长

SQL:
SELECT
  region,
  DATE_TRUNC('month', order_date) as month,
  SUM(amount) as monthly_revenue,
  ROW_NUMBER() OVER (PARTITION BY region ORDER BY DATE_TRUNC('month', order_date)) as month_rank,
  LAG(SUM(amount)) OVER (PARTITION BY region ORDER BY DATE_TRUNC('month', order_date)) as prev_month,
  ROUND((SUM(amount) - LAG(...)) / LAG(...) * 100, 2) as mom_growth_pct
FROM orders
GROUP BY region, DATE_TRUNC('month', order_date)
```

#### 组件4：Pivot（行转列）

```
用途：转换数据形状，生成交叉表

【UI操作】
├─ 1. 拖入 "Pivot" 组件
├─ 2. 配置行维度：
│  └─ Rows: region（作为行标签）
├─ 3. 配置列维度：
│  └─ Columns: month（作为列标签）
├─ 4. 配置值字段：
│  └─ Values: SUM(revenue)（单元格数值）
└─ 5. 处理空值：
   ├─ 填充为 0
   └─ 或留空

【示例】

输入数据（长格式）：
┌────────┬────────┬─────────┐
│ region │ month  │ revenue │
├────────┼────────┼─────────┤
│ 北区   │ Jan    │ 50,000  │
│ 北区   │ Feb    │ 55,000  │
│ 北区   │ Mar    │ 60,000  │
│ 南区   │ Jan    │ 40,000  │
│ 南区   │ Feb    │ 45,000  │
│ 南区   │ Mar    │ 50,000  │
└────────┴────────┴─────────┘

输出数据（宽格式）：
┌────────┬─────────┬─────────┬─────────┐
│ region │ Jan     │ Feb     │ Mar     │
├────────┼─────────┼─────────┼─────────┤
│ 北区   │ 50,000  │ 55,000  │ 60,000  │
│ 南区   │ 40,000  │ 45,000  │ 50,000  │
└────────┴─────────┴─────────┴─────────┘

【用途】
1. 生成报表（月度销售、地区对比）
2. 时间序列分析
3. 维度分析（SKU × 地区）
```

#### 组件5：Custom SQL（自定义 SQL）

```
用途：编写复杂的 SQL 逻辑

【UI操作】
├─ 1. 拖入 "Custom SQL" 组件
├─ 2. 连接上游表
├─ 3. 在编辑器中编写 SQL
│  └─ 表别名自动映射（input_1, input_2, ...)
├─ 4. 使用完整 Spark SQL 能力
│  ├─ 窗口函数
│  ├─ CTE（WITH 子句）
│  ├─ 复杂条件
│  └─ 正则表达式
└─ 5. 预览结果

【示例】
SELECT
  order_id,
  customer_id,
  order_amount,
  -- 派生字段1：订单优先级
  CASE
    WHEN order_amount > 100000 THEN 'VIP'
    WHEN order_amount > 50000 THEN 'HIGH'
    WHEN order_amount > 10000 THEN 'MEDIUM'
    ELSE 'LOW'
  END as priority,
  -- 派生字段2：超期天数
  DATEDIFF(NOW(), order_date) as days_since_order,
  -- 派生字段3：是否超期（超过 7 天）
  CASE
    WHEN DATEDIFF(NOW(), order_date) > 7 THEN true
    ELSE false
  END as is_overdue,
  -- 派生字段4：排名（按金额在同客户内排序）
  ROW_NUMBER() OVER (PARTITION BY customer_id ORDER BY order_amount DESC) as customer_order_rank
FROM input_1
WHERE order_status NOT IN ('CANCELLED', 'PENDING')
```

### 2.4 实战案例：完整订单 ETL 管道

```
【第1步】需求分析

业务需求：
├─ 需要构建"销售数据"中枢
├─ 整合订单、客户、产品三个源系统数据
├─ 支持基于优先级的订单分配
├─ 关键指标：订单处理周期、按时交付率
└─ 数据更新：每天 02:00 UTC

数据源清单：
├─ Oracle ERP: ORDERS（50M 行）、CUSTOMERS（100K）、PRODUCTS（10K）
├─ Salesforce: 销售代表信息
└─ S3: 历史订单存档

【第2步】Pipeline 设计

步骤1：输入节点
├─ Input 1：orders_raw（来自 Data Connection）
├─ Input 2：customers_dim（来自 Data Connection）
├─ Input 3：products_dim（来自 Data Connection）
└─ Input 4：sales_reps（来自 Salesforce）

步骤2：清洁订单数据
├─ 使用 Filter 组件
├─ 条件：
│  ├─ amount > 0
│  ├─ status NOT IN ('DRAFT', 'CANCELLED')
│  ├─ customer_id IS NOT NULL
│  └─ created_date >= DATE_SUB(TODAY(), INTERVAL 730 DAYS)
└─ 输出：orders_clean（45M 行，过滤率 90%）

步骤3：联接客户信息
├─ Join orders_clean ⟵ customers_dim
├─ Join 类型：LEFT JOIN
├─ Join 键：orders.customer_id = customers.customer_id
├─ 新增字段：customer_name, region, segment, email
└─ 输出：orders_with_customers（45M 行）

步骤4：联接产品信息
├─ 首先处理 ORDER_ITEMS（订单明细）
│  └─ Input：order_items_raw（150M 行）
├─ 联接逻辑：
│  ├─ 左表：order_items_raw
│  ├─ 右表：products_dim
│  ├─ Join 键：order_items.product_id = products.product_id
│  └─ 保留字段：product_name, category, price, cost
├─ 输出：order_items_with_products（150M 行）
└─ 关联到订单：
   ├─ 汇总订单总价、总数量、产品数
   └─ 输出：orders_enriched

步骤5：计算派生字段
├─ 使用 Custom SQL 组件
├─ 计算内容：
│  ├─ order_priority（基于金额）
│  ├─ processing_days（处理天数）
│  ├─ is_overdue（是否超期）
│  ├─ gross_margin（毛利率）
│  └─ customer_lifetime_value（客户生命周期价值）
└─ 输出：orders_with_derived（45M 行）

步骤6：分配销售代表
├─ Join orders ⟵ sales_reps（基于 region）
├─ 分配规则：
│  ├─ 按 region 匹配销售代表
│  ├─ 选择当前负责订单数最少的代表
│  └─ 优先级高的订单分配给资深销售
└─ 输出：orders_with_assignment（45M 行）

步骤7：生成最终输出
├─ Output 节点1：orders_final（联接所有数据）
├─ Output 节点2：daily_metrics（日度汇总）
│  ├─ 按 region 聚合
│  ├─ 计算日订单数、日收入、平均订单额
│  └─ 565 行（365天 × 多个地区）
└─ Output 节点3：assignment_queue（待分配订单）
   ├─ 筛选 status = 'CONFIRMED'
   └─ 按优先级排序

【第3步】配置与测试

参数化配置（支持动态调整）：
├─ $start_date：开始日期（默认：1年前）
├─ $min_amount：最小订单额（默认：0）
├─ $priority_threshold：优先级阈值（默认：NORMAL）
└─ $include_cancelled：是否包含已取消订单（默认：false）

使用参数在 Filter 中：
WHERE created_date >= $start_date
  AND amount >= $min_amount
  AND status NOT IN (CASE WHEN $include_cancelled THEN '' ELSE 'CANCELLED' END)

测试阶段：
├─ 开发环境运行
├─ 使用小数据量验证逻辑
├─ 检查输出结果
├─ 与业务部门比对验证
└─ 性能基准测试

【第4步】部署与监控

部署配置：
├─ 分支：feature/order-etl（开发）→ main（生产）
├─ 调度：每天 02:00 UTC 运行
├─ 重试策略：失败重试 3 次
├─ 告警：
│  ├─ 执行失败 → Slack 通知
│  ├─ 耗时 > 30 分钟 → 预警
│  └─ 输出行数异常（±50%）→ 告警

监控仪表盘：
┌──────────────────────────────────┐
│ 📊 Pipeline: order_processing    │
├──────────────────────────────────┤
│ 状态：✅ 运行中                   │
│ 最后执行：2024-01-16 02:00       │
│ 持续时间：2m 30s                 │
│                                  │
│ 数据统计：                       │
│ ├─ 输入：50.2M 行               │
│ ├─ 处理：45M 行（过滤 90%）     │
│ └─ 输出：45M 行                 │
│                                  │
│ 版本：v2.3 (2024-01-10)         │
│ 最近修改：修复客户名称字段      │
└──────────────────────────────────┘

【预期成果】
- 订单数据完整：100% 覆盖
- 数据新鲜度：每天更新
- 处理效率：2.5 分钟完成 50M 行
- 支持下游应用：20+ 个应用依赖
```

---

### 2.5 **关键步骤：Pipeline 输出映射到 Ontology 对象**

这是数据集转换为 Ontology 对象的**核心环节**，回答了"在什么地方、什么时候转换成 Ontology 对象（包括关系和 Action）"这个关键问题。

**答案**：在 **Pipeline 的输出节点（Output Node）** 配置映射，每次 Pipeline 运行时自动执行转换。

```
┌─────────────────────────────────────────────────────────────┐
│ Pipeline Output → Ontology Object 映射配置流程              │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│ 【步骤1】在 Pipeline 最后添加 Output 节点                   │
│ ├─ 拖入 "Output" 组件到画布                                │
│ ├─ 连接到最后一个转换节点                                  │
│ └─ 双击打开 Output 配置面板                                │
│                                                             │
│ 【步骤2】选择输出类型                                       │
│ ┌───────────────────────────────────────────────────┐     │
│ │ Output Configuration                              │     │
│ │ ├─ Output Name: orders_final                      │     │
│ │ ├─ Output Type:                                   │     │
│ │ │  ☐ Dataset Only (仅保存为数据集)                │     │
│ │ │  ☑ Map to Ontology Object (映射到本体对象)       │     │
│ │ └─ Description: 订单数据的 Ontology 映射          │     │
│ └───────────────────────────────────────────────────┘     │
│                                                             │
│ 【步骤3】选择或创建对象类型                                 │
│ ┌───────────────────────────────────────────────────┐     │
│ │ Select Object Type                                │     │
│ │                                                   │     │
│ │ 方式 A：选择已存在的对象类型                       │     │
│ │ ├─ 下拉菜单：[Order] (已在 Ontology Manager 定义) │     │
│ │ └─ 自动加载：Order 的所有属性和关系                │     │
│ │                                                   │     │
│ │ 方式 B：从 Pipeline 输出创建新对象类型             │     │
│ │ ├─ 点击按钮：[Create Object Type from Output]    │     │
│ │ ├─ 系统自动推断：                                 │     │
│ │ │  ├─ 主键候选：order_id (唯一性 100%)            │     │
│ │ │  ├─ 属性类型：自动识别 String/Double/DateTime   │     │
│ │ │  ├─ 关系候选：检测外键字段 (customer_id...)     │     │
│ │ │  └─ 显示名称：自动生成（驼峰转空格）            │     │
│ │ └─ 后续需在 Ontology Manager 中补充：            │     │
│ │    ├─ 派生属性逻辑                                │     │
│ │    ├─ Actions 定义                                │     │
│ │    └─ 权限规则                                    │     │
│ └───────────────────────────────────────────────────┘     │
│                                                             │
│ 【步骤4】配置字段映射（Field Mapping）                      │
│ ┌──────────────────────────────────────────────────────┐  │
│ │ Field Mapping: Dataset → Ontology                    │  │
│ │ ┌────────────────┬──────────────────────────────┐    │  │
│ │ │ Pipeline 字段   │ Ontology 属性               │    │  │
│ │ ├────────────────┼──────────────────────────────┤    │  │
│ │ │ order_id       │ id (Primary Key) ✓          │    │  │
│ │ │ order_number   │ orderNumber (String)        │    │  │
│ │ │ customer_id    │ customer (Link → Customer)  │ →  │  │
│ │ │ product_ids[]  │ products (Link[] → Product) │ →  │  │
│ │ │ total_amount   │ amount (Double)             │    │  │
│ │ │ order_status   │ status (Enum)               │    │  │
│ │ │ created_at     │ createdAt (DateTime)        │    │  │
│ │ │ updated_at     │ updatedAt (DateTime)        │    │  │
│ │ │ is_high_value  │ isHighValue (Boolean)       │    │  │
│ │ │ priority_level │ priority (Enum)             │    │  │
│ │ │ assigned_user  │ assignedTo (Link → User)    │ →  │  │
│ │ │ region         │ region (String)             │    │  │
│ │ └────────────────┴──────────────────────────────┘    │  │
│ │                                                      │  │
│ │ 映射规则：                                            │  │
│ │ ├─ 自动类型转换：String → Enum (如果已定义枚举)      │  │
│ │ ├─ 外键识别：*_id 字段自动识别为 Link               │  │
│ │ ├─ 数组字段：product_ids[] → products (Link[])      │  │
│ │ └─ 未映射字段：保留在数据集中，不出现在 Ontology    │  │
│ └──────────────────────────────────────────────────────┘  │
│                                                             │
│ 【步骤5】配置关系映射（Link Mapping）                       │
│ ┌──────────────────────────────────────────────────────┐  │
│ │ Relationship Configuration                           │  │
│ │                                                      │  │
│ │ ┌─────────────────────────────────────────────┐    │  │
│ │ │ Link 1: Order → Customer (Many-to-One)      │    │  │
│ │ ├─────────────────────────────────────────────┤    │  │
│ │ │ 源字段：customer_id (String)                │    │  │
│ │ │ 目标对象：Customer                          │    │  │
│ │ │ 匹配字段：Customer.id                       │    │  │
│ │ │ 关系名称：customer                          │    │  │
│ │ │ 反向关系：Customer.orders[] (自动创建)      │    │  │
│ │ │ 必填：☑ Yes                                │    │  │
│ │ │ 级联删除：☐ No                             │    │  │
│ │ └─────────────────────────────────────────────┘    │  │
│ │                                                      │  │
│ │ ┌─────────────────────────────────────────────┐    │  │
│ │ │ Link 2: Order → Product (Many-to-Many)      │    │  │
│ │ ├─────────────────────────────────────────────┤    │  │
│ │ │ 源字段：product_ids[] (Array<String>)       │    │  │
│ │ │ 连接表：order_items (必须)                  │    │  │
│ │ │   ├─ 外键1：order_items.order_id           │    │  │
│ │ │   └─ 外键2：order_items.product_id         │    │  │
│ │ │ 目标对象：Product                           │    │  │
│ │ │ 关系名称：products                          │    │  │
│ │ │ 反向关系：Product.orders[] (自动创建)       │    │  │
│ │ │ 必填：☑ Yes (至少1个产品)                   │    │  │
│ │ └─────────────────────────────────────────────┘    │  │
│ │                                                      │  │
│ │ ┌─────────────────────────────────────────────┐    │  │
│ │ │ Link 3: Order → User (Many-to-One, Optional)│    │  │
│ │ ├─────────────────────────────────────────────┤    │  │
│ │ │ 源字段：assigned_user (String, nullable)    │    │  │
│ │ │ 目标对象：User                              │    │  │
│ │ │ 匹配字段：User.email                        │    │  │
│ │ │ 关系名称：assignedTo                        │    │  │
│ │ │ 反向关系：User.assignedOrders[]            │    │  │
│ │ │ 必填：☐ No (可为空)                         │    │  │
│ │ │ 空值处理：NULL → 不建立关系                 │    │  │
│ │ └─────────────────────────────────────────────┘    │  │
│ └──────────────────────────────────────────────────────┘  │
│                                                             │
│ 【步骤6】配置更新策略（Update Strategy）                    │
│ ┌──────────────────────────────────────────────────────┐  │
│ │ Update Strategy                                      │  │
│ │ ├─ 模式：☑ UPSERT (Insert or Update)               │  │
│ │ │  └─ 基于主键：order_id                           │  │
│ │ ├─ 冲突解决：Last Write Wins                        │  │
│ │ ├─ 时间戳策略：                                      │  │
│ │ │  ├─ createdAt: 仅在插入时设置                    │  │
│ │ │  └─ updatedAt: 每次更新时刷新                    │  │
│ │ ├─ 删除策略：                                        │  │
│ │ │  ├─ 软删除：标记为 status = 'DELETED'            │  │
│ │ │  └─ 硬删除：☐ 不启用                             │  │
│ │ └─ 增量更新：                                        │  │
│ │    ├─ 增量字段：updated_at                         │  │
│ │    └─ 仅更新自上次同步后的变更行                   │  │
│ └──────────────────────────────────────────────────────┘  │
│                                                             │
│ 【步骤7】权限与审计                                         │
│ ├─ 权限继承：☑ 自动继承 Ontology Manager 中定义的权限      │
│ ├─ 审计日志：☑ 记录所有对象创建、更新、删除操作            │
│ └─ 数据血缘：☑ 自动追踪 Pipeline → Dataset → Ontology     │
│                                                             │
│ 【步骤8】测试与部署                                         │
│ ├─ 点击 [Test Mapping]：                                   │
│ │  ├─ 验证字段类型兼容性                                  │
│ │  ├─ 检查关系完整性（外键存在性）                        │
│ │  ├─ 模拟运行（小数据量）                                │
│ │  └─ 预览 Ontology 对象实例                             │
│ │                                                         │
│ └─ 点击 [Save & Deploy]：                                 │
│    ├─ 保存映射配置                                        │
│    ├─ 部署到生产环境                                      │
│    └─ 开始调度运行                                        │
└─────────────────────────────────────────────────────────────┘
```

**Pipeline 运行时的完整数据流**：

```
【运行时流程】每次 Pipeline 执行时

1️⃣ 数据处理阶段
├─ 读取源数据（Snowflake ORDERS_RAW 表）
├─ 执行 Filter（清洗脏数据）
├─ 执行 Join（关联维度表）
├─ 执行 Aggregate（聚合指标）
├─ 执行 Enrich（添加派生列）
└─ 输出到临时数据集：orders_processed

        ↓

2️⃣ Ontology 映射阶段（自动执行）
├─ 读取 orders_processed 数据集
├─ 执行字段映射（Dataset 字段 → Ontology 属性）
│  └─ 类型转换、枚举映射、数组处理
├─ 执行关系映射（建立对象间关系）
│  ├─ Order → Customer (通过 customer_id)
│  ├─ Order → Product[] (通过 order_items 连接表)
│  └─ Order → User (通过 assigned_user)
├─ 执行 UPSERT 操作：
│  ├─ 如果对象存在（基于主键）→ 更新属性
│  └─ 如果对象不存在 → 创建新对象
├─ 建立双向关系：
│  ├─ Order.customer → Customer
│  └─ Customer.orders[] ← Order
├─ 继承权限规则（从 Ontology Manager）
└─ 记录审计日志

        ↓

3️⃣ 结果输出
├─ 数据集层：orders_processed (Parquet 格式)
│  └─ 可供 Contour/Quiver 等工具直接分析
├─ Ontology 层：Order 对象实例
│  ├─ 1.05M 个 Order 对象
│  ├─ 包含所有属性、关系、派生属性
│  ├─ 可执行 Actions（Assign, Cancel, Escalate）
│  └─ 继承权限和审计规则
└─ 触发下游刷新：
   ├─ Workshop 应用自动刷新对象数据
   ├─ Contour 看板自动更新
   └─ AIP Agents 获取最新对象状态
```

**Actions 的定义与执行**：

```
┌──────────────────────────────────────────────────────┐
│ Actions 不在 Pipeline 中定义！                        │
├──────────────────────────────────────────────────────┤
│                                                      │
│ ❌ 错误理解：                                         │
│    以为 Actions 在 Pipeline Output 节点配置          │
│                                                      │
│ ✅ 正确流程：                                         │
│                                                      │
│ 【阶段1】定义 Actions (在 Ontology Manager 中)       │
│ ├─ 打开 Ontology Manager                            │
│ ├─ 选择 Order 对象类型                              │
│ ├─ 点击 [Add Action Type]                           │
│ ├─ 定义 Action: Assign (分配订单)                   │
│ │  ├─ 参数：                                        │
│ │  │  ├─ assignedTo: Link to User (必填)          │
│ │  │  ├─ reason: String (必填)                    │
│ │  │  └─ deadline: Date (可选)                    │
│ │  ├─ 前置条件：                                    │
│ │  │  ├─ status IN ['PENDING', 'CONFIRMED']      │
│ │  │  └─ assignedTo IS NULL                      │
│ │  ├─ 执行逻辑（TypeScript/Python）：              │
│ │  │  ```typescript                               │
│ │  │  async function assign(order, params) {      │
│ │  │    order.assignedTo = params.assignedTo;    │
│ │  │    order.status = 'ASSIGNED';               │
│ │  │    order.assignedAt = new Date();           │
│ │  │    await sendNotification(params.assignedTo);│
│ │  │  }                                            │
│ │  │  ```                                          │
│ │  └─ 权限：仅销售经理和管理员                      │
│ │                                                  │
│ ├─ 定义 Action: Cancel (取消订单)                   │
│ │  └─ (类似定义...)                                │
│ │                                                  │
│ └─ 保存并发布 Ontology                              │
│                                                      │
│ 【阶段2】绑定 Actions (在 Workshop 应用中)           │
│ ├─ 打开 Workshop 应用编辑器                         │
│ ├─ 添加 "Object Table" 组件（显示 Order 对象）     │
│ ├─ 添加 "Button Group" 组件                        │
│ ├─ 配置按钮：                                        │
│ │  ├─ 按钮文本：[分配订单]                         │
│ │  ├─ 绑定 Action：Order.Assign                   │
│ │  ├─ 参数来源：                                    │
│ │  │  ├─ assignedTo: 从下拉选择器获取             │
│ │  │  ├─ reason: 从文本框获取                     │
│ │  │  └─ 当前订单 ID: 自动从选中行获取            │
│ │  └─ 显示条件：当 order.status = 'PENDING' 时显示│
│ └─ 保存并发布应用                                    │
│                                                      │
│ 【阶段3】执行 Actions (用户在应用中触发)             │
│ ├─ 用户在 Workshop 中查看订单列表                   │
│ ├─ 选中一个 PENDING 状态的订单                      │
│ ├─ 点击 [分配订单] 按钮                             │
│ ├─ 填写弹窗表单：                                    │
│ │  ├─ 分配给：选择 User (销售代表 A)               │
│ │  └─ 原因：填写 "客户催单"                        │
│ ├─ 点击 [确认]                                      │
│ ├─ 系统执行：                                        │
│ │  ├─ 检查前置条件 ✓                               │
│ │  ├─ 执行 Action 逻辑 ✓                           │
│ │  ├─ 更新 Ontology 对象 ✓                        │
│ │  ├─ 记录审计日志 ✓                               │
│ │  ├─ 发送邮件通知 ✓                               │
│ │  └─ 刷新 UI ✓                                    │
│ └─ 结果：订单状态变为 'ASSIGNED'，显示分配信息     │
└──────────────────────────────────────────────────────┘
```

**关键时间点总结**：

| 阶段 | 在哪里 | 什么时候 | 做什么 |
|------|--------|----------|--------|
| **对象定义** | Ontology Manager | 设计阶段 | 定义对象结构、属性、关系 |
| **Actions 定义** | Ontology Manager | 设计阶段 | 定义操作类型、参数、执行逻辑、权限 |
| **映射配置** | Pipeline Builder Output 节点 | 开发阶段 | 配置字段映射、关系映射、更新策略 |
| **执行转换** | Pipeline 运行时 | 每次 Pipeline 运行 | 自动将数据集转换为 Ontology 对象 |
| **Actions 绑定** | Workshop 应用编辑器 | 应用开发阶段 | 将 Action 绑定到 UI 按钮 |
| **Actions 执行** | Workshop 应用 | 用户操作时 | 执行业务操作，更新对象 |

---

## 第3章：SQL 表达式 - 高阶查询

### 3.1 核心概念

**SQL 表达式板**允许使用完整的 Spark SQL，支持：

- **窗口函数**（ROW_NUMBER, RANK, LAG, LEAD）
- **复杂派生列**（CASE、IF、正则表达式）
- **高阶聚合**（PERCENTILE、STDDEV）
- **表达式库**（保存常用表达式）

### 3.2 常用 SQL 表达式

```sql
-- 【示例1】窗口函数：排序与排名
SELECT
  order_id,
  customer_id,
  order_amount,
  region,
  -- 在每个地区内排序
  ROW_NUMBER() OVER (PARTITION BY region ORDER BY order_amount DESC) as rank_in_region,
  -- 计算排名（相同金额同排名）
  RANK() OVER (PARTITION BY region ORDER BY order_amount DESC) as rank_with_tie,
  -- 计算累积和
  SUM(order_amount) OVER (PARTITION BY region ORDER BY order_amount DESC
                          ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as cumulative_sum
FROM orders;

-- 【示例2】时间序列分析
SELECT
  customer_id,
  DATE_TRUNC('month', order_date) as month,
  SUM(order_amount) as monthly_revenue,
  LAG(SUM(order_amount), 1, 0) OVER (
    PARTITION BY customer_id
    ORDER BY DATE_TRUNC('month', order_date)
  ) as prev_month_revenue,
  ROUND(
    (SUM(order_amount) - LAG(SUM(order_amount), 1, 0) OVER (...))
    / LAG(SUM(order_amount), 1, 1) OVER (...) * 100, 2
  ) as mom_growth_pct
FROM orders
GROUP BY customer_id, DATE_TRUNC('month', order_date)
ORDER BY customer_id, month;

-- 【示例3】客户分层
SELECT
  customer_id,
  customer_name,
  SUM(order_amount) as lifetime_value,
  CASE
    WHEN SUM(order_amount) > 100000 THEN 'VIP'
    WHEN SUM(order_amount) > 50000 THEN 'PREMIUM'
    WHEN SUM(order_amount) > 10000 THEN 'STANDARD'
    ELSE 'BASIC'
  END as customer_tier,
  COUNT(*) as order_count,
  AVG(order_amount) as avg_order_value
FROM orders
GROUP BY customer_id, customer_name
ORDER BY lifetime_value DESC;

-- 【示例4】异常检测
SELECT
  order_id,
  order_amount,
  AVG(order_amount) OVER () as avg_amount,
  STDDEV_POP(order_amount) OVER () as stddev_amount,
  ABS(order_amount - AVG(order_amount) OVER ()) / STDDEV_POP(order_amount) OVER () as z_score,
  CASE
    WHEN ABS(order_amount - AVG(order_amount) OVER ()) / STDDEV_POP(order_amount) OVER () > 3 THEN 'OUTLIER'
    ELSE 'NORMAL'
  END as is_anomaly
FROM orders;
```

---

## 第4章：Code Repositories - 生产级开发

### 4.1 核心概念

**Code Repositories** 支持生产级数据工程：

```
特点：
├─ Python/PySpark 编程
├─ 装饰器模式（将函数转为数据流程）
├─ Git 完整版本控制
├─ CI/CD 管道（自动测试、部署）
└─ 依赖管理（外部库、版本锁定）
```

### 4.2 基本用法

```python
# 【示例1】简单的数据转换

from foundry import transform_df
import pyspark.sql.functions as F

@transform_df
def process_orders(ctx):
    """处理订单数据的转换函数"""
    # 读取输入数据集
    df = ctx.input("orders_raw").dataframe()

    # 数据转换逻辑
    processed = (
        df
        # 过滤无效订单
        .filter(F.col("order_amount") > 0)
        .filter(F.col("customer_id").isNotNull())
        # 添加派生列
        .withColumn("order_year", F.year(F.col("order_date")))
        .withColumn("order_month", F.month(F.col("order_date")))
        # 按地区分组统计
        .groupBy("region", "order_year", "order_month")
        .agg(
            F.count("*").alias("order_count"),
            F.sum("order_amount").alias("total_revenue"),
            F.avg("order_amount").alias("avg_order_value")
        )
    )

    # 返回结果（自动保存为输出数据集）
    return processed

# 【示例2】多输入多输出函数

@transform_df
def enrich_orders_with_customer_data(ctx):
    """用客户数据丰富订单数据"""
    # 读取多个输入
    orders_df = ctx.input("orders").dataframe()
    customers_df = ctx.input("customers").dataframe()
    products_df = ctx.input("products").dataframe()

    # JOIN 数据
    enriched = (
        orders_df
        .join(customers_df, "customer_id", "left")
        .join(products_df, "product_id", "left")
        # 添加客户等级
        .withColumn(
            "customer_tier",
            F.when(F.col("lifetime_value") > 100000, "VIP")
             .when(F.col("lifetime_value") > 50000, "Premium")
             .otherwise("Standard")
        )
    )

    # 输出多个数据集
    ctx.output(enriched, "orders_enriched")
    ctx.output(
        enriched.filter(F.col("customer_tier") == "VIP"),
        "vip_orders"
    )

# 【示例3】带参数的数据处理

@transform_df
def process_orders_with_parameters(ctx):
    """支持运行时参数的数据处理"""
    # 从上下文获取参数
    min_order_amount = ctx.parameter("min_order_amount", default=0.0)
    target_region = ctx.parameter("target_region", default="All")

    df = ctx.input("orders").dataframe()

    # 根据参数过滤
    if target_region != "All":
        df = df.filter(F.col("region") == target_region)

    result = df.filter(F.col("order_amount") >= min_order_amount)

    return result

# 【示例4】生产级 ETL 函数

import logging

@transform_df
def production_grade_etl(ctx):
    """生产级 ETL 函数，包含日志、错误处理"""

    logger = logging.getLogger("order_processing")
    logger.info("开始处理订单数据")

    try:
        df = ctx.input("orders").dataframe()
        logger.info(f"读取 {df.count()} 行订单数据")

        # 数据质量检查
        null_check = df.filter(F.col("order_id").isNull()).count()
        if null_check > 0:
            logger.warning(f"发现 {null_check} 条 order_id 为空")

        # 主要处理逻辑
        result = (
            df
            .filter(F.col("order_amount") > 0)
            .filter(F.col("status").isin(['CONFIRMED', 'SHIPPED', 'DELIVERED']))
            # ... 更多转换 ...
        )

        logger.info(f"处理完成，输出 {result.count()} 行")
        return result

    except Exception as e:
        logger.error(f"处理失败: {str(e)}", exc_info=True)
        raise
```

### 4.3 Git 工作流

```
【开发流程】

1. 创建特性分支（本地开发）
   git checkout -b feature/order-processing

2. 编写与测试代码
   # 编辑 .py 文件
   # 本地运行测试

3. 提交代码
   git add .
   git commit -m "Add order processing ETL"

4. 推送并创建 Pull Request
   git push origin feature/order-processing
   # 在 Foundry UI 中创建 PR

5. 代码审查
   # 邀请同事 review
   # 解决 comments

6. Merge 到 Main
   # 自动触发构建与部署
   # Pipeline 在生产环境运行

7. 监控与告警
   # 查看执行结果
   # 设置性能告警
```

---

## 性能优化指南

### 优化1：数据分区

```sql
-- ❌ 不好：单一大表，全表扫描
SELECT * FROM orders WHERE order_date > '2024-01-01'

-- ✅ 好：表已按月分区
-- Foundry 自动只读取 >2024-01-01 的分区
-- 减少 I/O 成本 80%+
SELECT * FROM orders WHERE order_date > '2024-01-01'

-- 建议：在 Pipeline 输出时指定分区
-- 按 order_date 月份分区
-- 按 region 地区分区
```

### 优化2：物化与缓存

```
【需求】多个报告都需要计算"月度销售汇总"

❌ 不好做法：每个报告都运行相同的聚合
- 浪费计算资源
- 查询慢

✅ 好做法：创建物化表
1. 在 Pipeline 中构建"monthly_sales_summary"
2. 每月 01:00 自动运行
3. 报告直接查询物化表（<1秒）
4. 成本减少 10 倍
```

### 优化3：Join 优化

```
【问题】两个大表 JOIN 导致内存溢出

❌ 不好：
ORDERS (50M) JOIN CUSTOMERS (100M) → 爆炸

✅ 解决方案：
1. 先对 CUSTOMERS 执行 DISTINCT
2. 再进行 JOIN
3. 减少右表大小

❌ 不好：
SELECT * FROM orders o
JOIN customers c ON o.customer_id = c.customer_id
JOIN products p ON o.product_id = p.product_id

✅ 好：
SELECT * FROM orders o
JOIN (SELECT DISTINCT customer_id FROM customers) c
  ON o.customer_id = c.customer_id
JOIN (SELECT DISTINCT product_id FROM products) p
  ON o.product_id = p.product_id
```

---

## 最佳实践与避坑

### 最佳实践

```
1. 参数化您的 Pipeline
   - 用 $date_range 代替硬编码日期
   - 便于复用与时间序列处理

2. 版本控制与代码审查
   - 所有 ETL 代码必须通过 PR 审核
   - 保证代码质量与文档

3. 监控与告警
   - 配置数据量异常告警
   - 配置执行时间告警
   - 配置失败重试与通知

4. 数据质量检查
   - Pipeline 中嵌入 DQ 检查
   - NULL 检查、重复检查、范围检查

5. 增量同步而非全量
   - 使用增量模式 (Incremental/CDC)
   - 仅处理新/变更数据
   - 成本和速度都提升
```

### 常见错误与避坑

| 错误 | 症状 | 解决方案 |
|------|------|---------|
| **内存溢出** | Job 失败，无结果 | 添加 Filter 早期过滤；使用分区 |
| **JOIN 超时** | 查询卡住 | 检查 JOIN 条件是否为 NULL；使用广播 JOIN |
| **时间戳不对齐** | 增量 Sync 重复/漏掉数据 | 确保时间戳单调递增；使用 CDC 更安全 |
| **笛卡尔积** | 输出行数突增 | 检查 JOIN 条件；避免无条件 JOIN |
| **数据倾斜** | 某个分区极慢 | 使用 Salt 加盐；或增加 Shuffle 分区数 |

---

## 总结与下一步

### 关键要点

✅ **Pipeline Builder**：无代码 ETL，快速构建
✅ **SQL 表达式**：高阶分析，复杂逻辑
✅ **Code Repositories**：生产级代码，完整版本控制
✅ **性能优化**：分区、物化、Join 优化

### 下一步学习

- 📘 **本体数据层**：Data Connection、Ontology Manager、权限体系
- 📙 **分析层**：Contour、Quiver、Data Lineage
- 📗 **应用层**：Workshop、Notepad、Object Explorer
- 📕 **AI层**：AIP Logic、AIP Agents、MLOps

---

